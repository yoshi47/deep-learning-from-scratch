{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"ijUSTYEo-4Po","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653443004105,"user_tz":-540,"elapsed":27551,"user":{"displayName":"よしき","userId":"07538783130042353475"}},"outputId":"d06898ea-cb5a-453f-ab9e-29fa07c04bdc"},"id":"ijUSTYEo-4Po","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import sys, os\n","sys.path.append('/content/drive/MyDrive/Colab Notebooks/Book/deep-learning-from-scratch')"],"metadata":{"id":"Ux29LrMBYGAT","executionInfo":{"status":"ok","timestamp":1653443004108,"user_tz":-540,"elapsed":48,"user":{"displayName":"よしき","userId":"07538783130042353475"}}},"id":"Ux29LrMBYGAT","execution_count":2,"outputs":[]},{"cell_type":"code","source":["!git clone https://github.com/yoshi47/deep-learning-from-scratch.git"],"metadata":{"id":"d9VGafVEmQRc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653443005023,"user_tz":-540,"elapsed":958,"user":{"displayName":"よしき","userId":"07538783130042353475"}},"outputId":"99224b2e-2b9a-457f-f376-ed19f0b6305a"},"id":"d9VGafVEmQRc","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'deep-learning-from-scratch'...\n","remote: Enumerating objects: 460, done.\u001b[K\n","remote: Counting objects: 100% (7/7), done.\u001b[K\n","remote: Compressing objects: 100% (6/6), done.\u001b[K\n","remote: Total 460 (delta 1), reused 4 (delta 1), pack-reused 453\u001b[K\n","Receiving objects: 100% (460/460), 5.55 MiB | 20.75 MiB/s, done.\n","Resolving deltas: 100% (236/236), done.\n"]}]},{"cell_type":"markdown","source":["1章　Python入門\n","    1.1　Pythonとは\n","    1.2　Pythonのインストール\n","        1.2.1　Pythonのバージョン\n","        1.2.2　使用する外部ライブラリ\n","        1.2.3　Anacondaディストリビューション\n","    1.3　Pythonインタプリタ\n","        1.3.1　算術計算\n","        1.3.2　データ型\n","        1.3.3　変数\n","        1.3.4　リスト\n","        1.3.5　ディクショナリ\n","        1.3.6　ブーリアン\n","        1.3.7　if文\n","        1.3.8　for文\n","        1.3.9　関数\n","    1.4　Pythonスクリプトファイル\n","        1.4.1　ファイルに保存\n","        1.4.2　クラス\n","    1.5　NumPy\n","        1.5.1　NumPyのインポート\n","        1.5.2　NumPy配列の生成\n","        1.5.3　NumPyの算術計算\n","        1.5.4　NumPyのN次元配列\n","        1.5.5　ブロードキャスト\n","        1.5.6　要素へのアクセス\n","    1.6　Matplotlib\n","        1.6.1　単純なグラフの描画\n","        1.6.2　pyplotの機能\n","        1.6.3　画像の表示\n","    1.7　まとめ\n","\n","2章　パーセプトロン\n","    2.1　パーセプトロンとは\n","    2.2　単純な論理回路\n","        2.2.1　ANDゲート\n","        2.2.2　NANDゲートとORゲート\n","    2.3　パーセプトロンの実装\n","        2.3.1　簡単な実装\n","        2.3.2　重みとバイアスの導入\n","        2.3.3　重みとバイアスによる実装\n","    2.4　パーセプトロンの限界\n","        2.4.1　XORゲート\n","        2.4.2　線形と非線形\n","    2.5　多層パーセプトロン\n","        2.5.1　既存ゲートの組み合わせ\n","        2.5.2　XORゲートの実装\n","    2.6　NANDからコンピュータへ\n","    2.7　まとめ\n","\n","3章　ニューラルネットワーク\n","    3.1　パーセプトロンからニューラルネットワークへ\n","        3.1.1　ニューラルネットワークの例\n","        3.1.2　パーセプトロンの復習\n","        3.1.3　活性化関数の登場\n","    3.2　活性化関数\n","        3.2.1　シグモイド関数\n","        3.2.2　ステップ関数の実装\n","        3.2.3　ステップ関数のグラフ\n","        3.2.4　シグモイド関数の実装\n","        3.2.5　シグモイド関数とステップ関数の比較\n","        3.2.6　非線形関数\n","        3.2.7　ReLU関数\n","    3.3　多次元配列の計算\n","        3.3.1　多次元配列\n","        3.3.2　行列の内積\n","        3.3.3　ニューラルネットワークの内積\n","    3.4　3層ニューラルネットワークの実装\n","        3.4.1　記号の確認\n","        3.4.2　各層における信号伝達の実装\n","        3.4.3　実装のまとめ\n","    3.5　出力層の設計\n","        3.5.1　恒等関数とソフトマックス関数\n","        3.5.2　ソフトマックス関数の実装上の注意\n","        3.5.3　ソフトマックス関数の特徴\n","        3.5.4　出力層のニューロンの数\n","    3.6　手書き数字認識\n","        3.6.1　MNISTデータセット\n","        3.6.2　ニューラルネットワークの推論処理\n","        3.6.3　バッチ処理\n","    3.7　まとめ\n","\n","4章　ニューラルネットワークの学習\n","    4.1　データから学習する\n","        4.1.1　データ駆動\n","        4.1.2　訓練データとテストデータ\n","    4.2　損失関数\n","        4.2.1　2乗和誤差\n","        4.2.2　交差エントロピー誤差\n","        4.2.3　ミニバッチ学習\n","        4.2.4　［バッチ対応版］交差エントロピー誤差の実装\n","        4.2.5　なぜ損失関数を設定するのか？\n","    4.3　数値微分\n","        4.3.1　微分\n","        4.3.2　数値微分の例\n","        4.3.3　偏微分\n","    4.4　勾配\n","        4.4.1　勾配法\n","        4.4.2　ニューラルネットワークに対する勾配\n","    4.5　学習アルゴリズムの実装\n","        4.5.1　2層ニューラルネットワークのクラス\n","        4.5.2　ミニバッチ学習の実装\n","        4.5.3　テストデータで評価\n","    4.6　まとめ\n","\n","5章　誤差逆伝播法\n","    5.1　計算グラフ\n","        5.1.1　計算グラフで解く\n","        5.1.2　局所的な計算\n","        5.1.3　なぜ計算グラフで解くのか？\n","    5.2　連鎖率\n","        5.2.1　計算グラフの逆伝播\n","        5.2.2　連鎖率とは\n","        5.2.3　連鎖率と計算グラフ\n","    5.3　逆伝播\n","        5.3.1　加算ノードの逆伝播\n","        5.3.2　乗算ノードの逆伝播\n","        5.3.3　リンゴの例\n","    5.4　単純なレイヤの実装\n","        5.4.1　乗算レイヤの実装\n","        5.4.2　加算レイヤの実装\n","    5.5　活性化関数レイヤの実装\n","        5.5.1　ReLUレイヤ\n","        5.5.2　Sigmoidレイヤ\n","    5.6　A.ne／Softmaxレイヤの実装\n","        5.6.1　A.neレイヤ\n","        5.6.2　バッチ版A.neレイヤ\n","        5.6.3　Softmax-with-Lossレイヤ\n","    5.7　誤差逆伝播法の実装\n","        5.7.1　ニューラルネットワークの学習の全体図\n","        5.7.2　誤差逆伝播法に対応したニューラルネットワークの実装\n","        5.7.3　誤差逆伝播法の勾配確認\n","        5.7.4　誤差逆伝播法を使った学習\n","    5.8　まとめ\n","\n","6章　学習に関するテクニック\n","    6.1　パラメータの更新\n","        6.1.1　冒険家の話\n","        6.1.2　SGD\n","        6.1.3　SGDの欠点\n","        6.1.4　Momentum\n","        6.1.5　AdaGrad\n","        6.1.6　Adam\n","        6.1.7　どの更新手法を用いるか？\n","        6.1.8　MNISTデータセットによる更新手法の比較\n","    6.2　重みの初期値\n","        6.2.1　重みの初期値を0にする？\n","        6.2.2　隠れ層のアクティベーション分布\n","        6.2.3　ReLUの場合の重みの初期値\n","        6.2.4　MNISTデータセットによる重み初期値の比較\n","    6.3　Batch Normalization\n","        6.3.1　Batch Normalizationのアルゴリズム\n","        6.3.2　Batch Normalizationの評価\n","    6.4　正則化\n","        6.4.1　過学習\n","        6.4.2　Weight decay\n","        6.4.3　Dropout\n","    6.5　ハイパーパラメータの検証\n","        6.5.1　検証データ\n","        6.5.2　ハイパーパラメータの最適化\n","        6.5.3　ハイパーパラメータ最適化の実装\n","    6.6　まとめ\n","\n","7章　畳み込みニューラルネットワーク\n","    7.1　全体の構造\n","    7.2　畳み込み層\n","        7.2.1　全結合層の問題点\n","        7.2.2　畳み込み演算\n","        7.2.3　パディング\n","        7.2.4　ストライド\n","        7.2.5　3次元データの畳み込み演算\n","        7.2.6　ブロックで考える\n","        7.2.7　バッチ処理\n","    7.3　プーリング層\n","        7.3.1　プーリング層の特徴\n","    7.4　Convolution／Poolingレイヤの実装\n","        7.4.1　4次元配列\n","        7.4.2　im2colによる展開\n","        7.4.3　Convolutionレイヤの実装\n","        7.4.4　Poolingレイヤの実装\n","    7.5　CNNの実装\n","    7.6　CNNの可視化\n","        7.6.1　1層目の重みの可視化\n","        7.6.2　階層構造による情報抽出\n","    7.7　代表的なCNN\n","        7.7.1　LeNet\n","        7.7.2　AlexNet\n","    7.8　まとめ\n","\n","8章　ディープラーニング\n","    8.1　ネットワークをより深く\n","        8.1.1　よりディープなネットワークへ\n","        8.1.2　さらに認識精度を高めるには\n","        8.1.3　層を深くすることのモチベーション\n","    8.2　ディープラーニングの小歴史\n","        8.2.1　ImageNet\n","        8.2.2　VGG\n","        8.2.3　GoogLeNet\n","        8.2.4　ResNet\n","    8.3　ディープラーニングの高速化\n","        8.3.1　取り組むべき問題\n","        8.3.2　GPUによる高速化\n","        8.3.3　分散学習\n","        8.3.4　演算精度のビット削減\n","    8.4　ディープラーニングの実用例\n","        8.4.1　物体検出\n","        8.4.2　セグメンテーション\n","        8.4.3　画像キャプション生成\n","    8.5　ディープラーニングの未来\n","        8.5.1　画像スタイル変換\n","        8.5.2　画像生成\n","        8.5.3　自動運転\n","        8.5.4　Deep Q-Network（強化学習）\n","    8.6　まとめ\n"],"metadata":{"id":"PoFSR5e46vwp"},"id":"PoFSR5e46vwp"},{"cell_type":"markdown","id":"touched-savings","metadata":{"id":"touched-savings"},"source":["# ２章 パーセプトロン"]},{"cell_type":"markdown","id":"express-nevada","metadata":{"id":"express-nevada"},"source":["ANDゲート：２つの入力が１のときだけ１を出力し、それ以外は０を出力\n","\n","NANDゲート：Not AND ２つの入力が１のときだけ０を出力し、それ以外は１を出力\n","\n","ORゲート：入力信号の少なくともひとつが１であれば、出力が１になる"]},{"cell_type":"markdown","id":"executed-determination","metadata":{"id":"executed-determination"},"source":["## パーセプトロンの実装"]},{"cell_type":"markdown","id":"closing-rider","metadata":{"id":"closing-rider"},"source":["簡単な実装"]},{"cell_type":"code","execution_count":null,"id":"fossil-flashing","metadata":{"id":"fossil-flashing"},"outputs":[],"source":["def AND(x1, x2):\n","    w1, w2, theta = 0.5, 0.5, 0.7\n","    tmp = x1*w1 + x2*w2\n","    if tmp <= theta:\n","        return 0\n","    elif tmp > theta:\n","        return 1"]},{"cell_type":"code","execution_count":null,"id":"conservative-contact","metadata":{"id":"conservative-contact"},"outputs":[],"source":["AND(0, 0), AND(1, 0), AND(0, 1), AND(1, 1)"]},{"cell_type":"markdown","id":"interested-bradley","metadata":{"id":"interested-bradley"},"source":["重みとバイアスの導入"]},{"cell_type":"markdown","id":"operational-animation","metadata":{"id":"operational-animation"},"source":["バイアスは発火のしやすさーー出力信号が１を出力する度合いーー"]},{"cell_type":"code","execution_count":null,"id":"cloudy-passport","metadata":{"id":"cloudy-passport"},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","execution_count":null,"id":"surgical-parallel","metadata":{"id":"surgical-parallel"},"outputs":[],"source":["# 入力\n","x = np.array([0, 1])\n","# 重み\n","w = np.array([0.5, 0.5])\n","# バイアス\n","b = -0.7"]},{"cell_type":"code","execution_count":null,"id":"black-commissioner","metadata":{"id":"black-commissioner"},"outputs":[],"source":["w*x"]},{"cell_type":"code","execution_count":null,"id":"secure-throw","metadata":{"id":"secure-throw"},"outputs":[],"source":["np.sum(w*x) + b"]},{"cell_type":"markdown","id":"identical-sodium","metadata":{"id":"identical-sodium"},"source":["重みとバイアスによる実装"]},{"cell_type":"markdown","id":"classical-grocery","metadata":{"id":"classical-grocery"},"source":["重みとバイアスだけが変わる"]},{"cell_type":"markdown","id":"weighted-leonard","metadata":{"id":"weighted-leonard"},"source":["ANDゲート：２つの入力が１のときだけ１を出力し、それ以外は０を出力"]},{"cell_type":"code","execution_count":null,"id":"later-monroe","metadata":{"id":"later-monroe"},"outputs":[],"source":["def AND(x1, x2):\n","    x = np.array([x1, x2])\n","    w = np.array([0.5, 0.5])\n","    b = -0.7\n","    tmp = np.sum(w*x) + b\n","    if tmp <= 0:\n","        return 0\n","    else:\n","        return 1"]},{"cell_type":"code","execution_count":null,"id":"lesser-player","metadata":{"id":"lesser-player"},"outputs":[],"source":["(AND(0, 0), AND(1, 0), AND(0, 1), AND(1, 1))"]},{"cell_type":"markdown","id":"recreational-remark","metadata":{"id":"recreational-remark"},"source":["NANDゲート：Not AND ２つの入力が１のときだけ０を出力し、それ以外は１を出力"]},{"cell_type":"code","execution_count":null,"id":"conscious-consumption","metadata":{"id":"conscious-consumption"},"outputs":[],"source":["def NAND(x1, x2):\n","    x = np.array([x1, x2])\n","    w = np.array([-0.5, -0.5])\n","    b = 0.7\n","    tmp = np.sum(w*x) + b\n","    if tmp <= 0:\n","        return 0\n","    else:\n","        return 1"]},{"cell_type":"code","execution_count":null,"id":"criminal-christmas","metadata":{"id":"criminal-christmas"},"outputs":[],"source":["(NAND(0, 0), NAND(1, 0), NAND(0, 1), NAND(1, 1))"]},{"cell_type":"markdown","id":"continuing-measure","metadata":{"id":"continuing-measure"},"source":["ORゲート：入力信号の少なくともひとつが１であれば、出力が１になる"]},{"cell_type":"code","execution_count":null,"id":"acceptable-riding","metadata":{"id":"acceptable-riding"},"outputs":[],"source":["def OR(x1, x2):\n","    x = np.array([x1, x2])\n","    w = np.array([0.5, 0.5])\n","    b = -0.2\n","    tmp = np.sum(w*x) + b\n","    if tmp <= 0:\n","        return 0\n","    else:\n","        return 1"]},{"cell_type":"code","execution_count":null,"id":"immune-writing","metadata":{"id":"immune-writing"},"outputs":[],"source":["(OR(0, 0), OR(1, 0), OR(0, 1), OR(1, 1))"]},{"cell_type":"markdown","id":"international-roads","metadata":{"id":"international-roads"},"source":["## パーセプトロンの限界"]},{"cell_type":"markdown","id":"accessory-ghana","metadata":{"id":"accessory-ghana"},"source":["XORゲート：２つの入力のどちらかが１のときだけ出力が１になる"]},{"cell_type":"markdown","id":"precious-spotlight","metadata":{"id":"precious-spotlight"},"source":["排他的論理和"]},{"cell_type":"markdown","id":"polyphonic-brain","metadata":{"pycharm":{"name":"#%% md\n"},"id":"polyphonic-brain"},"source":["## 多層パーセプトロン"]},{"cell_type":"markdown","id":"0a57e713","metadata":{"id":"0a57e713"},"source":["NANDゲート\\\n","           ＞ANDゲート\n","ORゲート　/"]},{"cell_type":"code","execution_count":null,"id":"d8a10f1b","metadata":{"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"id":"d8a10f1b"},"outputs":[],"source":["def XOR(x1, x2):\n","    s1 = NAND(x1, x2)\n","    s2 = OR(x1, x2)\n","    y = AND(s1, s2)\n","    return y"]},{"cell_type":"code","execution_count":null,"id":"985e91f3","metadata":{"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"id":"985e91f3"},"outputs":[],"source":["(XOR(0, 0), XOR(1, 0), XOR(0, 1), XOR(1, 1))"]},{"cell_type":"markdown","id":"2f8eadb8","metadata":{"id":"2f8eadb8"},"source":["ANDやORが単相のパーセプトロンであったのに対して、XORは２層のパーセプトロン\n","\n","層を複数重ねたパーセプトロンを多層パーセプトロンと言うことがある"]},{"cell_type":"markdown","id":"1e5f82cb","metadata":{"pycharm":{"name":"#%% md\n"},"id":"1e5f82cb"},"source":["## まとめ"]},{"cell_type":"markdown","id":"2eb68255","metadata":{"pycharm":{"name":"#%% md\n"},"id":"2eb68255"},"source":["パーセプトロンはニューラルネットワークの基礎"]},{"cell_type":"markdown","id":"e6975f23","metadata":{"pycharm":{"name":"#%% md\n"},"id":"e6975f23"},"source":["# ３章 ニューラルネットワーク"]},{"cell_type":"markdown","id":"9388b533","metadata":{"pycharm":{"name":"#%% md\n"},"id":"9388b533"},"source":["適切な重みパラメータをデータから自動で学習できる"]},{"cell_type":"markdown","id":"8118a9be","metadata":{"pycharm":{"name":"#%% md\n"},"id":"8118a9be"},"source":["## パーセプトロンからニューラルネットワークへ"]},{"cell_type":"markdown","id":"193af166","metadata":{"pycharm":{"name":"#%% md\n"},"id":"193af166"},"source":["**活性化関数**：入力信号の総和を出力信号に変換する関数"]},{"cell_type":"markdown","id":"30c7aded","metadata":{"pycharm":{"name":"#%% md\n"},"id":"30c7aded"},"source":["## 活性化関数"]},{"cell_type":"markdown","id":"c39a44da","metadata":{"pycharm":{"name":"#%% md\n"},"id":"c39a44da"},"source":["### ステップ関数の実装"]},{"cell_type":"markdown","id":"1bbd6594","metadata":{"pycharm":{"name":"#%% md\n"},"id":"1bbd6594"},"source":["入力が０を超えたら１を出力し、それ以外は０を出力する"]},{"cell_type":"code","execution_count":null,"id":"45b48142","metadata":{"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"id":"45b48142"},"outputs":[],"source":["def step_function(x):\n","    if x > 0:\n","        return 1\n","\n","    else:\n","        return 0"]},{"cell_type":"markdown","id":"703123de-8239-497a-ae64-e480135de2a8","metadata":{"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"id":"703123de-8239-497a-ae64-e480135de2a8"},"source":["NumPy配列に対応する"]},{"cell_type":"code","execution_count":null,"id":"2ded93d1-eb3c-47ee-ba65-7bb3087c8b5b","metadata":{"id":"2ded93d1-eb3c-47ee-ba65-7bb3087c8b5b"},"outputs":[],"source":["def step_function(x):\n","    y = x > 0\n","    return y.astype(np.int)"]},{"cell_type":"markdown","id":"08f5423c-4f71-4e82-95ea-de898a97f5ff","metadata":{"id":"08f5423c-4f71-4e82-95ea-de898a97f5ff"},"source":["yはboolの配列、値になる"]},{"cell_type":"code","execution_count":null,"id":"3978287d-37d2-4519-9459-5207a3475a1b","metadata":{"id":"3978287d-37d2-4519-9459-5207a3475a1b"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pylab as plt\n","\n","def step_function(x):\n","    return np.array(x > 0, dtype=np.int64)\n","\n","x = np.arange(-5.0, 5.0, 0.1)\n","y = step_function(x)\n","plt.plot(x, y)\n","plt.ylim(-0.1, 1.1)\n","plt.show()"]},{"cell_type":"markdown","id":"e769659f-9f37-438e-b6fa-f6a3d8c9cf20","metadata":{"id":"e769659f-9f37-438e-b6fa-f6a3d8c9cf20"},"source":["### シグモイド関数の実装"]},{"cell_type":"code","execution_count":null,"id":"7301ca93-a267-4e3a-a144-5435e6e7fbe7","metadata":{"id":"7301ca93-a267-4e3a-a144-5435e6e7fbe7"},"outputs":[],"source":["def sigmoid(x):\n","    return 1 / (1 + np.exp(-x))"]},{"cell_type":"code","execution_count":null,"id":"4c2e04bf-f524-4445-8ea2-a90b2059d877","metadata":{"id":"4c2e04bf-f524-4445-8ea2-a90b2059d877"},"outputs":[],"source":["x = np.arange(-5.0, 5.0, 0.1)\n","y = sigmoid(x)\n","plt.plot(x, y)\n","plt.ylim(-0.1, 1.1)\n","plt.show()"]},{"cell_type":"markdown","id":"7fbb6279-9031-4ff9-88bd-a43ed3cdc971","metadata":{"id":"7fbb6279-9031-4ff9-88bd-a43ed3cdc971"},"source":["パーセプトロンは０か１のどちらかしか返さない\n","\n","ニューラルネットワークは連続的な実数値の信号が流れる"]},{"cell_type":"markdown","id":"776969a0-cecf-4930-8c63-007b6232861f","metadata":{"id":"776969a0-cecf-4930-8c63-007b6232861f"},"source":["どちらも非線形関数（真っ直ぐでない）"]},{"cell_type":"markdown","id":"c443c726-1f42-4981-92d8-f33237b32228","metadata":{"id":"c443c726-1f42-4981-92d8-f33237b32228"},"source":["### ReLU関数"]},{"cell_type":"markdown","id":"4d89138d-4d6c-4857-94b4-2cdb7ac71aa8","metadata":{"id":"4d89138d-4d6c-4857-94b4-2cdb7ac71aa8"},"source":["入力が０を超えていれば、その入力をそのまま出力し、０以下ならば０を出力する関数"]},{"cell_type":"code","execution_count":null,"id":"1b77bb47-03f4-488c-8e1f-4102c2b97a53","metadata":{"id":"1b77bb47-03f4-488c-8e1f-4102c2b97a53"},"outputs":[],"source":["def relu(x):\n","    return np.maximun(0, x)"]},{"cell_type":"markdown","id":"49215b42-fc3d-4129-87f6-8bd86feb872b","metadata":{"id":"49215b42-fc3d-4129-87f6-8bd86feb872b"},"source":["## 多次元配列の計算"]},{"cell_type":"code","execution_count":null,"id":"5948cc76-e831-4c66-b567-d9c32b196651","metadata":{"id":"5948cc76-e831-4c66-b567-d9c32b196651"},"outputs":[],"source":["X = np.array([1, 2])\n","W = np.array([[1, 3, 5], [2, 4, 6]])\n","\n","Y = np.dot(X, W)\n","print(Y)"]},{"cell_type":"markdown","id":"c2bebde4-dd1c-482b-ba57-56d2a13f4c23","metadata":{"id":"c2bebde4-dd1c-482b-ba57-56d2a13f4c23"},"source":["## ３層ニューラルネットワークの実装"]},{"cell_type":"code","execution_count":null,"id":"cf7db538-2311-43c9-94c7-3ab579757b01","metadata":{"id":"cf7db538-2311-43c9-94c7-3ab579757b01"},"outputs":[],"source":["X = np.array([1.0, 0.5])\n","W1 = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])\n","B1 = np.array([0.1, 0.2, 0.3])\n","\n","print(W1.shape)\n","print(X.shape)\n","print(B1.shape)\n","\n","A1 = np.dot(X, W1) + B1"]},{"cell_type":"code","execution_count":null,"id":"1c29964d-b51f-4315-bd4c-1ba8389f5c1d","metadata":{"id":"1c29964d-b51f-4315-bd4c-1ba8389f5c1d"},"outputs":[],"source":["Z1 = sigmoid(A1)\n","print(A1)\n","print(Z1)"]},{"cell_type":"code","execution_count":null,"id":"ada67fba-f794-44bc-ae41-d968fd1b6ed3","metadata":{"id":"ada67fba-f794-44bc-ae41-d968fd1b6ed3"},"outputs":[],"source":["W2 = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])\n","B2 = np.array([0.1, 0.2])\n","\n","print(Z1.shape)\n","print(W2.shape)\n","print(B2.shape)\n","\n","A2 = np.dot(Z1, W2) + B2\n","Z2 = sigmoid(A2)"]},{"cell_type":"code","execution_count":null,"id":"c19438b2-472b-423f-a2a7-786a71b0b9f4","metadata":{"id":"c19438b2-472b-423f-a2a7-786a71b0b9f4"},"outputs":[],"source":["def identity_function(x):\n","    return x"]},{"cell_type":"code","execution_count":null,"id":"945f72a7-bf71-49ee-9f10-3b1f2c6dfaa4","metadata":{"id":"945f72a7-bf71-49ee-9f10-3b1f2c6dfaa4"},"outputs":[],"source":["W3 = np.array([[0.1, 0.3], [0.2, 0.4]])\n","B3 = np.array([0.1, 0.2])\n","\n","A3 = np.dot(Z2, W3) + B3\n","Y = identity_function(A3)"]},{"cell_type":"markdown","id":"f52490fd-9c0d-449a-aee3-6eb3c68d5e4a","metadata":{"id":"f52490fd-9c0d-449a-aee3-6eb3c68d5e4a"},"source":["実装のまとめ"]},{"cell_type":"code","execution_count":null,"id":"16794c74-4d6c-4b4a-938f-ed4c4cdd1c6d","metadata":{"id":"16794c74-4d6c-4b4a-938f-ed4c4cdd1c6d"},"outputs":[],"source":["def init_network():\n","    network = {}\n","    network['W1'] = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])\n","    network['b1'] = np.array([0.1, 0.2, 0.3])\n","    network['W2'] = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])\n","    network['b2'] = np.array([0.1, 0.2])\n","    network['W3'] = np.array([[0.1, 0.3], [0.2, 0.4]])\n","    network['b3'] = np.array([0.1, 0.2])\n","    \n","    return network\n","\n","\n","def forward(network, x):\n","    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n","    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n","    \n","    a1 = np.dot(x, W1) + b1\n","    z1 = sigmoid(a1)\n","    a2 = np.dot(z1, W2) + b2\n","    z2 = sigmoid(a2)\n","    a3 = np.dot(z2, W3) + b3\n","    y = identity_function(a3)\n","    \n","    return y\n","\n","network = init_network()\n","\n","x = np.array([1.0, 0.5])\n","y = forward(network, x)\n","print(y)"]},{"cell_type":"code","execution_count":null,"id":"2837570f-b931-4949-9958-c8c7abbaca9f","metadata":{"id":"2837570f-b931-4949-9958-c8c7abbaca9f"},"outputs":[],"source":["a = np.array([0.3, 2.9, 4.0])\n","\n","exp_a = np.exp(a)\n","print(exp_a)"]},{"cell_type":"markdown","id":"90d81614-abd0-4b7d-ae31-88bd9ddbb917","metadata":{"id":"90d81614-abd0-4b7d-ae31-88bd9ddbb917"},"source":["### ソフトマックス関数"]},{"cell_type":"code","execution_count":null,"id":"df4e750f-7f55-4843-8a84-3aaef67ecdb2","metadata":{"id":"df4e750f-7f55-4843-8a84-3aaef67ecdb2"},"outputs":[],"source":["sum_exp_a = np.sum(exp_a)\n","print(sum_exp_a)"]},{"cell_type":"code","execution_count":null,"id":"15704f03-b664-40a1-b1a1-5db775ec7938","metadata":{"id":"15704f03-b664-40a1-b1a1-5db775ec7938"},"outputs":[],"source":["y = exp_a / sum_exp_a\n","print(y)"]},{"cell_type":"code","execution_count":null,"id":"bd3d3427-f390-4d95-bc7b-f45a71477427","metadata":{"id":"bd3d3427-f390-4d95-bc7b-f45a71477427"},"outputs":[],"source":["def softmax(a):\n","    exp_a = np.exp(a)\n","    sum_exp_a = np.sum(exp_a)\n","    y = exp_a / sum_exp_a\n","    \n","    return y"]},{"cell_type":"markdown","id":"acb1164b-09ae-4783-8859-071d260b06b1","metadata":{"id":"acb1164b-09ae-4783-8859-071d260b06b1"},"source":["ソフトマックス関数 オーバーフローに気をつける"]},{"cell_type":"code","execution_count":null,"id":"b6c3ee64-7889-495d-868b-1660d2b56863","metadata":{"id":"b6c3ee64-7889-495d-868b-1660d2b56863"},"outputs":[],"source":["a = np.array([1010, 1000, 990])\n","np.exp(a) / np.sum(np.exp(a))"]},{"cell_type":"markdown","id":"ec116ba7-2fc4-45b8-8233-e40f2c2fd27e","metadata":{"id":"ec116ba7-2fc4-45b8-8233-e40f2c2fd27e"},"source":["オーバーフロー対策"]},{"cell_type":"code","execution_count":null,"id":"430035e6-a42e-481c-99e1-5e617ff2231b","metadata":{"id":"430035e6-a42e-481c-99e1-5e617ff2231b"},"outputs":[],"source":["c = np.max(a)\n","print(a - c)"]},{"cell_type":"code","execution_count":null,"id":"3261a17f-570f-4a6e-beaa-23f6d179e505","metadata":{"id":"3261a17f-570f-4a6e-beaa-23f6d179e505"},"outputs":[],"source":["np.exp(a - c) / np.sum(np.exp(a - c))"]},{"cell_type":"code","execution_count":null,"id":"15f0e3b9-2549-4417-a924-c90b84f2d82c","metadata":{"id":"15f0e3b9-2549-4417-a924-c90b84f2d82c"},"outputs":[],"source":["def softmax(a):\n","    c = np.max(a)\n","    exp_a = np.exp(a - c)\n","    sum_exp_a = np.sum(exp_a)\n","    y = exp_a / sum_exp_a\n","    \n","    return y"]},{"cell_type":"code","execution_count":null,"id":"eca5daec-b373-4dcd-9039-e68ec3d2a537","metadata":{"id":"eca5daec-b373-4dcd-9039-e68ec3d2a537"},"outputs":[],"source":["a = np.array([0.3, 2.9, 4.0])\n","y = softmax(a)\n","print(y)\n","np.sum(y)"]},{"cell_type":"markdown","id":"49cd61ce-a854-43f9-ba1a-6a5ab292c2ed","metadata":{"id":"49cd61ce-a854-43f9-ba1a-6a5ab292c2ed"},"source":["ソフトマックス関数の出力の総和は１になる"]},{"cell_type":"markdown","id":"d2248c8a-1bb4-455f-bb7c-da6fa47190fd","metadata":{"id":"d2248c8a-1bb4-455f-bb7c-da6fa47190fd"},"source":["## 手書き数字認識"]},{"cell_type":"markdown","source":["MNISTデータセット：手書き数字の画像セット"],"metadata":{"id":"37ebf3c0-1503-47f1-9086-db5178fcf0e7"},"id":"37ebf3c0-1503-47f1-9086-db5178fcf0e7"},{"cell_type":"code","source":["import sys, os\n","\n","sys.path.append('/content/drive/MyDrive/Colab Notebooks/Book/deep-learning-from-scratch')"],"metadata":{"id":"cal9Aq_zAPsO"},"id":"cal9Aq_zAPsO","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from dataset.mnist import load_mnist\n","\n","(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=False)"],"metadata":{"id":"vC1wSe3hujNc"},"id":"vC1wSe3hujNc","execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(x_train.shape)\n","print(t_train.shape)\n","print(x_test.shape)\n","print(t_test.shape)\n"],"metadata":{"id":"OTfbf81vurTq"},"id":"OTfbf81vurTq","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["load_mnist関数は、「（訓練画像、訓練ラベル）、（テスト画像、テストラベル）」でデータを返す"],"metadata":{"id":"GYSzXV5yuwmY"},"id":"GYSzXV5yuwmY"},{"cell_type":"code","source":["import numpy as np\n","from PIL import Image\n","from IPython.display import display\n","\n","\n","def img_show(img):\n","  pil_img = Image.fromarray(np.uint8(img))\n","  pil_img.show()\n","  display(pil_img)\n","\n","img = x_train[0]\n","label = t_train[0]\n","print(label)\n","\n","print(img.shape)\n","img = img.reshape(28, 28)\n","print(img.shape)\n","img_show(img)\n"],"metadata":{"id":"jv4bTluCwrhF"},"id":"jv4bTluCwrhF","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pickle\n","\n","def get_data():\n","  (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, flatten=True, one_hot_label=False)\n","  return x_test, t_test\n","\n","def init_network():\n","  with open('/content/drive/MyDrive/Colab Notebooks/Book/deep-learning-from-scratch/ch03/sample_weight.pkl', 'rb') as f:\n","    network = pickle.load(f)\n","\n","  return network\n","\n","def predict(network, x):\n","  W1, W2, W3 = network['W1'], network['W2'], network['W3']\n","  b1, b2, b3 = network['b1'], network['b2'], network['b3']\n","  \n","  a1 = np.dot(x, W1) + b1\n","  z1 = sigmoid(a1)\n","  a2 = np.dot(z1, W2) + b2\n","  z2 = sigmoid(a2)\n","  a3 = np.dot(z2, W3) + b3\n","  y = softmax(a3)\n","\n","  return y"],"metadata":{"id":"IuDVOLBtxsz3"},"id":"IuDVOLBtxsz3","execution_count":null,"outputs":[]},{"cell_type":"code","source":["x, t = get_data()\n","network = init_network()\n","\n","accuracy_cnt = 0\n","for i in range(len(x)):\n","  y = predict(network, x[i])\n","  p = np.argmax(y)\n","  if p == t[i]:\n","    accuracy_cnt += 1\n","\n","print('Accuracy:' + str(float(accuracy_cnt) / len(x)))"],"metadata":{"id":"ir3kypC10XdR"},"id":"ir3kypC10XdR","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**正規化**：データを有るまとまった範囲に変換する処理\n","\n","**白色化**：データ全体の分布の形状を均一にする"],"metadata":{"id":"7p1aIL4hvJ3J"},"id":"7p1aIL4hvJ3J"},{"cell_type":"code","source":["x, _ = get_data()\n","network = init_network()\n","W1, W2, W3 = network['W1'], network['W2'], network['W3']\n","\n","print(x.shape)\n","print(x[0].shape)\n","print(W1.shape)\n","print(W2.shape)\n","print(W3.shape)"],"metadata":{"id":"42d4IlCR09dp"},"id":"42d4IlCR09dp","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**バッチ**：まとまりのある入力データ\n","\n","バッチ処理を行うと高速に効率よく処理できる"],"metadata":{"id":"pf1ry9yYub93"},"id":"pf1ry9yYub93"},{"cell_type":"code","source":["x, t = get_data()\n","network = init_network()\n","\n","batch_size = 100\n","accuracy_cnt = 0\n","\n","for i in range(0, len(x), batch_size):\n","  x_batch = x[i:i+batch_size]\n","  y_batch = predict(network, x_batch)\n","  p = np.argmax(y_batch, axis=1)\n","  accuracy_cnt += np.sum(p == t[i:i+batch_size])\n","\n","print('Accuracy:' + str(float(accuracy_cnt) / len(x)))"],"metadata":{"id":"1jyqWgbCvo18"},"id":"1jyqWgbCvo18","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## まとめ"],"metadata":{"id":"dLyE4O-AxCsv"},"id":"dLyE4O-AxCsv"},{"cell_type":"markdown","source":["ニューラルネットワークは活性化関数に滑らかに変化する関数を使う"],"metadata":{"id":"nyj78DikxBuM"},"id":"nyj78DikxBuM"},{"cell_type":"markdown","source":["# ４章ニューラルネットワークの学習"],"metadata":{"id":"KJcGg1LQxbQt"},"id":"KJcGg1LQxbQt"},{"cell_type":"markdown","source":["学習：訓練データから適切な重みパラメータを自動で獲得することを目指す"],"metadata":{"id":"X_ohI8Hi0EgW"},"id":"X_ohI8Hi0EgW"},{"cell_type":"markdown","source":["## 訓練データとテストデータ"],"metadata":{"id":"fKgTsV7mVU-O"},"id":"fKgTsV7mVU-O"},{"cell_type":"markdown","source":["## 損失関数"],"metadata":{"id":"_rUvrSKnYFsG"},"id":"_rUvrSKnYFsG"},{"cell_type":"markdown","source":["### 二条和誤差"],"metadata":{"id":"c482OQo2Y90o"},"id":"c482OQo2Y90o"},{"cell_type":"code","source":["def sum_squared_error(y, t):\n","  return 0.5 * np.sum((y-t)**2)"],"metadata":{"id":"298-arVqYJLf"},"id":"298-arVqYJLf","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 「２」を正解とする\n","t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]"],"metadata":{"id":"zpWhEze6cgCa"},"id":"zpWhEze6cgCa","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 例1：「2」の確率が最も高い場合（0.6）\n","y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n","\n","sum_squared_error(np.array(y), np.array(t))"],"metadata":{"id":"z6PVwqGsbgnQ"},"id":"z6PVwqGsbgnQ","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 例2：「7」の確率が最も高い場合（0.6）\n","y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n","\n","sum_squared_error(np.array(y), np.array(t))"],"metadata":{"id":"ZiP-oeVvb4VN"},"id":"ZiP-oeVvb4VN","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["上の方があっているので誤差が小さい"],"metadata":{"id":"i5bUlQGvc7ns"},"id":"i5bUlQGvc7ns"},{"cell_type":"markdown","source":["### 交差エントロピー誤差"],"metadata":{"id":"5zHSvCdNdHKE"},"id":"5zHSvCdNdHKE"},{"cell_type":"markdown","source":["xが０に近づくにつれてyの値はどんどん小さくなる"],"metadata":{"id":"HLGAXeBkpe8S"},"id":"HLGAXeBkpe8S"},{"cell_type":"code","source":["def cross_entropy_error(y, t):\n","  # マイナス無限大を発生させないように\n","  delta = 1e-7\n","  return -np.sum(t * np.log(y + delta))"],"metadata":{"id":"vEfF7N6PcrlC"},"id":"vEfF7N6PcrlC","execution_count":null,"outputs":[]},{"cell_type":"code","source":["t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n","y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n","cross_entropy_error(np.array(y), np.array(t))"],"metadata":{"id":"X89IA75yqGHj"},"id":"X89IA75yqGHj","execution_count":null,"outputs":[]},{"cell_type":"code","source":["y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n","cross_entropy_error(np.array(y), np.array(t))"],"metadata":{"id":"9MN2fVdHqiVL"},"id":"9MN2fVdHqiVL","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ミニバッチ学習"],"metadata":{"id":"eQTU3vce_TQd"},"id":"eQTU3vce_TQd"},{"cell_type":"markdown","source":["データの中から一部を選び出し、その一部のデータを全体の「近似」として利用する"],"metadata":{"id":"hJxxho1xGon9"},"id":"hJxxho1xGon9"},{"cell_type":"markdown","source":["ミニバッチごとに学習を行う"],"metadata":{"id":"TF_oXGgBG-SK"},"id":"TF_oXGgBG-SK"},{"cell_type":"code","source":["import sys, os\n","sys.path.append('/content/drive/MyDrive/Colab Notebooks/Book/deep-learning-from-scratch')\n","\n","import numpy as np\n","from dataset.mnist import load_mnist\n","\n","(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n","\n","print(x_train.shape)\n","print(t_train.shape)"],"metadata":{"id":"QeTmJgxOqmK-"},"id":"QeTmJgxOqmK-","execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_size = x_train.shape[0]\n","batch_size = 10\n","batch_mask = np.random.choice(train_size, batch_size)\n","x_batch = x_train[batch_mask]\n","t_batch = t_train[batch_mask]"],"metadata":{"id":"vhPLNgWJIAbM"},"id":"vhPLNgWJIAbM","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### [バッチ対応版] 交差エントロピー誤差の実装"],"metadata":{"id":"mPJLPdbTIgRF"},"id":"mPJLPdbTIgRF"},{"cell_type":"code","source":["def cross_entropy_error(y, t):\n","  if y.ndim == 1:\n","    t = t.reshape(1, t.size)\n","    y = y.reshape(1, y.size)\n","\n","  batch_size = y.shape[0]\n","  return -np.sum(t * np.log(y + 1e-7)) / batch_size"],"metadata":{"id":"bCVrX0FKI_34"},"id":"bCVrX0FKI_34","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["教師データがラベルとして与えられたとき（２、５，７など）"],"metadata":{"id":"xG_hIh_FJpjP"},"id":"xG_hIh_FJpjP"},{"cell_type":"code","source":["def cross_entropy_error(y, t):\n","  if y.ndim == 1:\n","    t = t.reshape(1, t.size)\n","    y = y.reshape(1, y.size)\n","\n","  batch_size = y.shape[0]\n","  return -np.sum(np.log(y[np.arrage(batch_size), t]+ 1e-7)) / batch_size"],"metadata":{"id":"S5v2onG_J9Zj"},"id":"S5v2onG_J9Zj","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 数値微分"],"metadata":{"id":"yh3EnF2HKaBB"},"id":"yh3EnF2HKaBB"},{"cell_type":"markdown","source":["小さすぎる値は正しく表現できない"],"metadata":{"id":"oehJrdfriQlO"},"id":"oehJrdfriQlO"},{"cell_type":"markdown","source":["### 微分"],"metadata":{"id":"8Ta_EnTlsR0Z"},"id":"8Ta_EnTlsR0Z"},{"cell_type":"code","source":["def numerical_diff(f, x):\n","  h = 1e-4\n","  return (f(x+h) - f(x-h)) / (2*h)"],"metadata":{"id":"hRjF8tI9hza-"},"id":"hRjF8tI9hza-","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["$$ y=0.01x^2+0.1x $$"],"metadata":{"id":"CYcy14GSjMkN"},"id":"CYcy14GSjMkN"},{"cell_type":"code","source":["def function_1(x):\n","  return 0.01*x**2 + 0.1*x"],"metadata":{"id":"K0xNDZFnjBe2"},"id":"K0xNDZFnjBe2","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","x = np.arange(0.0, 20.0, 0.1)\n","y = function_1(x)\n","plt.xlabel(\"x\")\n","plt.ylabel(\"f(x)\")\n","plt.plot(x, y)\n","plt.show()"],"metadata":{"id":"5bEugdmumONk"},"id":"5bEugdmumONk","execution_count":null,"outputs":[]},{"cell_type":"code","source":["numerical_diff(function_1, 5)"],"metadata":{"id":"1H_u69Vgmssz"},"id":"1H_u69Vgmssz","execution_count":null,"outputs":[]},{"cell_type":"code","source":["numerical_diff(function_1, 10)"],"metadata":{"id":"DQDv9huFrCXg"},"id":"DQDv9huFrCXg","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 偏微分"],"metadata":{"id":"yH1WZAGrrFpf"},"id":"yH1WZAGrrFpf"},{"cell_type":"markdown","source":["$$ f(x_{0},x_{1})=x_0^2+x_1^2 $$"],"metadata":{"id":"TODLHOGOsWKW"},"id":"TODLHOGOsWKW"},{"cell_type":"code","source":["def function_2(x):\n","  return x[0]**2 + x[1]**2\n","  # または return np.sum(x**2)"],"metadata":{"id":"8fod8yvDs6RN"},"id":"8fod8yvDs6RN","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 勾配"],"metadata":{"id":"0lo1kTF0tQpH"},"id":"0lo1kTF0tQpH"},{"cell_type":"code","source":["def numerical_gradient(f, x: np.array) -> np.array:\n","  h = 1e-4\n","  grad = np.zeros_like(x)\n","\n","  for idx in range(x.size):\n","    tmp_val = x[idx]\n","\n","    # f(x+h)の計算\n","    x[idx] = tmp_val + h\n","    fxh1 = f(x)\n","\n","    # f(x-h)の計算\n","    x[idx] = tmp_val - h\n","    fxh2 = f(x)\n","\n","    grad[idx] = (fxh1 - fxh2) / (2*h)\n","    x[idx] = tmp_val\n","\n","  return grad"],"metadata":{"id":"kT-8_69svFkU"},"id":"kT-8_69svFkU","execution_count":null,"outputs":[]},{"cell_type":"code","source":["numerical_gradient(function_2, np.array([3.0, 4.0]))"],"metadata":{"id":"8Gm7_pdgMD7E"},"id":"8Gm7_pdgMD7E","execution_count":null,"outputs":[]},{"cell_type":"code","source":["numerical_gradient(function_2, np.array([0.0, 2.0]))"],"metadata":{"id":"PVj05BgsNmJf"},"id":"PVj05BgsNmJf","execution_count":null,"outputs":[]},{"cell_type":"code","source":["numerical_gradient(function_2, np.array([3.0, 0.0]))"],"metadata":{"id":"qu9nELcPfyuA"},"id":"qu9nELcPfyuA","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["購買が示す方向は、各場所において**関数の値を最も減らす方向**"],"metadata":{"id":"hNCaAX2hhqkF"},"id":"hNCaAX2hhqkF"},{"cell_type":"markdown","source":["勾配降下法"],"metadata":{"id":"V5byqxsliyu0"},"id":"V5byqxsliyu0"},{"cell_type":"code","source":["def gradient_descent(f, init_x, lr=0.01, step_num=100):\n","  x = init_x\n","\n","  for i in range(step_num):\n","    grad = numerical_gradient(f, x)\n","    x -= lr * grad\n","\n","  return x"],"metadata":{"id":"ANvbuTohf51h"},"id":"ANvbuTohf51h","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["関数の極小値を求めることができる\n","\n","うまくいけば最小値を求めることができる"],"metadata":{"id":"N9FzCeVAjaVZ"},"id":"N9FzCeVAjaVZ"},{"cell_type":"code","source":["init_x = np.array([-3.0, 4.0])\n","\n","gradient_descent(function_2, init_x=init_x, lr=0.1, step_num=100)"],"metadata":{"id":"2qxfHfyHkCYh"},"id":"2qxfHfyHkCYh","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import ch04.gradient_method"],"metadata":{"id":"zDqLZRLny7Rf"},"id":"zDqLZRLny7Rf","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["学習率が大きすぎる例：lr=10.0"],"metadata":{"id":"OQeY5blt0Fqn"},"id":"OQeY5blt0Fqn"},{"cell_type":"code","source":["init_x = np.array([-3.0, 4.0])\n","gradient_descent(function_2, init_x=init_x, lr=10.0, step_num=100)"],"metadata":{"id":"paens7W2zEI1"},"id":"paens7W2zEI1","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["学習率が小さすぎる例：lr=1e-10"],"metadata":{"id":"QPPrw_490hL1"},"id":"QPPrw_490hL1"},{"cell_type":"code","source":["init_x = np.array([-3.0, 4.0])\n","gradient_descent(function_2, init_x=init_x, lr=1e-10, step_num=100)"],"metadata":{"id":"AcuEOy2U0dpL"},"id":"AcuEOy2U0dpL","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["適切な学習率を設定することが重要"],"metadata":{"id":"wqdmX0_307ds"},"id":"wqdmX0_307ds"},{"cell_type":"code","source":["import sys, os\n","sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n","import numpy as np\n","from common.functions import softmax, cross_entropy_error\n","from common.gradient import numerical_gradient\n","\n","\n","class simpleNet:\n","    def __init__(self):\n","        self.W = np.random.randn(2,3)\n","\n","    def predict(self, x):\n","        return np.dot(x, self.W)\n","\n","    def loss(self, x, t):\n","        z = self.predict(x)\n","        y = softmax(z)\n","        loss = cross_entropy_error(y, t)\n","\n","        return loss\n","\n","x = np.array([0.6, 0.9])\n","t = np.array([0, 0, 1])\n","\n","net = simpleNet()\n","\n","f = lambda w: net.loss(x, t)\n","dW = numerical_gradient(f, net.W)\n","\n","print(dW)"],"metadata":{"id":"nLs38Phu03xH"},"id":"nLs38Phu03xH","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 学習アルゴリズムの実装"],"metadata":{"id":"0rj0xTmOBE_2"},"id":"0rj0xTmOBE_2"},{"cell_type":"markdown","source":["\n","\n","-   前提\n","\n","  ニューラルネットワークは、適応可能な重みとバイアスがあり、この重みとバイアスを訓練データに適応するように調整することを「学習」と呼ぶ。ニューラルネットワークの学習は次の4つの手順で行う。\n","-   ステップ1（ミニバッチ）\n","\n","  訓練データの中からランダムに一部のデータを選び出す。その選ばれたデータをミニバッチと言い、ここでは、そのミニバッチの損失関数の値を減らすことを目的とする。\n","- ステップ2（勾配の算出）\n","\n","  ミニバッチの損失関数を減らすために、各重みパラメータの勾配を求める。勾配は、損失関数の値を最も減らす方向を示す。\n","- ステップ3（パラメータの更新）\n","\n","  重みパラメータを勾配方向に微小量だけ更新する。\n","- ステップ4（繰り返す）\n","\n","  ステップ1、ステップ2、ステップ3を繰り返す。\n"],"metadata":{"id":"UfizXEymCwzI"},"id":"UfizXEymCwzI"},{"cell_type":"code","source":["# coding: utf-8\n","import sys, os\n","sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n","from common.functions import *\n","from common.gradient import numerical_gradient\n","import numpy as np\n","\n","\n","class TwoLayerNet:\n","\n","    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n","        # 重みの初期化\n","        self.params = {}\n","        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n","        self.params['b1'] = np.zeros(hidden_size)\n","        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n","        self.params['b2'] = np.zeros(output_size)\n","\n","    def predict(self, x):\n","        W1, W2 = self.params['W1'], self.params['W2']\n","        b1, b2 = self.params['b1'], self.params['b2']\n","    \n","        a1 = np.dot(x, W1) + b1\n","        z1 = sigmoid(a1)\n","        a2 = np.dot(z1, W2) + b2\n","        y = softmax(a2)\n","        \n","        return y\n","        \n","    # x:入力データ, t:教師データ\n","    def loss(self, x, t):\n","        y = self.predict(x)\n","        \n","        return cross_entropy_error(y, t)\n","    \n","    def accuracy(self, x, t):\n","        y = self.predict(x)\n","        y = np.argmax(y, axis=1)\n","        t = np.argmax(t, axis=1)\n","        \n","        accuracy = np.sum(y == t) / float(x.shape[0])\n","        return accuracy\n","        \n","    # x:入力データ, t:教師データ\n","    def numerical_gradient(self, x, t):\n","        loss_W = lambda W: self.loss(x, t)\n","        \n","        grads = {}\n","        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n","        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n","        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n","        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n","        \n","        return grads\n","        \n","    def gradient(self, x, t):\n","        W1, W2 = self.params['W1'], self.params['W2']\n","        b1, b2 = self.params['b1'], self.params['b2']\n","        grads = {}\n","        \n","        batch_num = x.shape[0]\n","        \n","        # forward\n","        a1 = np.dot(x, W1) + b1\n","        z1 = sigmoid(a1)\n","        a2 = np.dot(z1, W2) + b2\n","        y = softmax(a2)\n","        \n","        # backward\n","        dy = (y - t) / batch_num\n","        grads['W2'] = np.dot(z1.T, dy)\n","        grads['b2'] = np.sum(dy, axis=0)\n","        \n","        dz1 = np.dot(dy, W2.T)\n","        da1 = sigmoid_grad(a1) * dz1\n","        grads['W1'] = np.dot(x.T, da1)\n","        grads['b1'] = np.sum(da1, axis=0)\n","\n","        return grads"],"metadata":{"id":"CZ8jRq5TACJP"},"id":"CZ8jRq5TACJP","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["ミニバッチ学習の実装\n","\n","テストデータで評価"],"metadata":{"id":"WCTQ1t9V--KN"},"id":"WCTQ1t9V--KN"},{"cell_type":"code","source":["# coding: utf-8\n","import sys, os\n","sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from dataset.mnist import load_mnist\n","from ch04.two_layer_net import TwoLayerNet\n","\n","# データの読み込み\n","(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n","\n","network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n","\n","iters_num = 10000  # 繰り返しの回数を適宜設定する\n","train_size = x_train.shape[0]\n","batch_size = 100\n","learning_rate = 0.1\n","\n","train_loss_list = []\n","train_acc_list = []\n","test_acc_list = []\n","\n","iter_per_epoch = max(train_size / batch_size, 1)\n","\n","for i in range(iters_num):\n","    batch_mask = np.random.choice(train_size, batch_size)\n","    x_batch = x_train[batch_mask]\n","    t_batch = t_train[batch_mask]\n","    \n","    # 勾配の計算\n","    #grad = network.numerical_gradient(x_batch, t_batch)\n","    grad = network.gradient(x_batch, t_batch)\n","    \n","    # パラメータの更新\n","    for key in ('W1', 'b1', 'W2', 'b2'):\n","        network.params[key] -= learning_rate * grad[key]\n","    \n","    loss = network.loss(x_batch, t_batch)\n","    train_loss_list.append(loss)\n","    \n","    if i % iter_per_epoch == 0:\n","        train_acc = network.accuracy(x_train, t_train)\n","        test_acc = network.accuracy(x_test, t_test)\n","        train_acc_list.append(train_acc)\n","        test_acc_list.append(test_acc)\n","        print(\"train acc, test acc | \" + str(train_acc) + \", \" + str(test_acc))\n","\n","# グラフの描画\n","markers = {'train': 'o', 'test': 's'}\n","x = np.arange(len(train_acc_list))\n","plt.plot(x, train_acc_list, label='train acc')\n","plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n","plt.xlabel(\"epochs\")\n","plt.ylabel(\"accuracy\")\n","plt.ylim(0, 1.0)\n","plt.legend(loc='lower right')\n","plt.show()"],"metadata":{"id":"_G5FmggB-1k8"},"id":"_G5FmggB-1k8","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## まとめ"],"metadata":{"id":"XlAnJa0kA6zb"},"id":"XlAnJa0kA6zb"},{"cell_type":"markdown","source":["ニューラルネットワークが学習できるように、損失関数という「指標」を導入した\n","\n","損失関数を基準として、その値が最も小さくなる重みパラメータを出すことが、ニューラルネットワークの学習の目標"],"metadata":{"id":"qAwCLXwe_l2q"},"id":"qAwCLXwe_l2q"},{"cell_type":"markdown","source":["# 誤差逆伝播法"],"metadata":{"id":"Qo3WUz37BoAU"},"id":"Qo3WUz37BoAU"},{"cell_type":"markdown","source":["数値微分はシンプルだが計算に時間がかかる\n","\n","誤差逆伝播法：重みパラメータのコウバイの計算を効率よく行う手法"],"metadata":{"id":"ul8-WrNhVmBp"},"id":"ul8-WrNhVmBp"},{"cell_type":"markdown","source":["## 計算グラフ"],"metadata":{"id":"cGI8vLDbXQwC"},"id":"cGI8vLDbXQwC"},{"cell_type":"markdown","source":["## 連鎖律"],"metadata":{"id":"vL3BDyeSBjjs"},"id":"vL3BDyeSBjjs"},{"cell_type":"markdown","source":["合成関数の微分と一緒"],"metadata":{"id":"fqFdxr57dlKw"},"id":"fqFdxr57dlKw"},{"cell_type":"markdown","source":["## 逆伝播"],"metadata":{"id":"yS0AHKP4dZI5"},"id":"yS0AHKP4dZI5"},{"cell_type":"markdown","source":["## 単純なレイヤの実装"],"metadata":{"id":"uTPF5i-WiXOz"},"id":"uTPF5i-WiXOz"},{"cell_type":"code","source":["class MulLayer:\n","  def __init__(self):\n","    self.x = None\n","    self.y = None\n","\n","  def forward(self, x, y):\n","    self.x = x\n","    self.y = y\n","    out = x * y\n","\n","    return out\n","\n","  def backward(self, dout):\n","    dx = dout * self.y  # ｘとｙをひっくり返す\n","    dy = dout * self.x\n","\n","    return dx, dy\n"],"metadata":{"id":"yEgpoPRhiacK"},"id":"yEgpoPRhiacK","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["乗算レイヤを使った順伝播"],"metadata":{"id":"idDmmdv9kHsY"},"id":"idDmmdv9kHsY"},{"cell_type":"code","source":["apple = 100\n","apple_num = 2\n","tax = 1.1\n","\n","# layer\n","mul_apple_layer = MulLayer()\n","mul_tax_layer = MulLayer()\n","\n","# forword\n","apple_price = mul_apple_layer.forward(apple, apple_num)\n","price = mul_tax_layer.forward(apple_price, tax)\n","\n","print(price)"],"metadata":{"id":"d3-gwtbXjb_4"},"id":"d3-gwtbXjb_4","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["各変数に関する微分"],"metadata":{"id":"3IpBOjwSkWru"},"id":"3IpBOjwSkWru"},{"cell_type":"markdown","source":["微分（dout）"],"metadata":{"id":"18uDSmBT3prR"},"id":"18uDSmBT3prR"},{"cell_type":"code","source":["# backward\n","dprice = 1\n","dapple_price, dtax = mul_tax_layer.backward(dprice)\n","dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n","\n","print(dapple, dapple_num, dtax)"],"metadata":{"id":"GgSFBe92kEC3"},"id":"GgSFBe92kEC3","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["加算レイヤの実装"],"metadata":{"id":"9pqEqREX4dC1"},"id":"9pqEqREX4dC1"},{"cell_type":"code","source":["class AddLayer:\n","  def __init__(self):\n","    pass\n","\n","  def forward(self, x, y):\n","    out = x + y\n","    return out\n","\n","  def backward(self, dout):\n","    dx = dout * 1\n","    dy = dout * 1\n","    return dx, dy"],"metadata":{"id":"29FF-4eJ0hfz"},"id":"29FF-4eJ0hfz","execution_count":null,"outputs":[]},{"cell_type":"code","source":["apple = 100\n","apple_num = 2\n","orange = 150\n","orange_num = 3\n","tax = 1.1\n","\n","# layer\n","mul_apple_layer = MulLayer()\n","mul_orange_layer = MulLayer()\n","add_apple_orange_layer = AddLayer()\n","mul_tax_layer = MulLayer()\n","\n","# forward\n","apple_price = mul_apple_layer.forward(apple, apple_num)\n","orange_price = mul_orange_layer.forward(orange, orange_num)\n","all_price = add_apple_orange_layer.forward(apple_price, orange_price)\n","price = mul_tax_layer.forward(all_price, tax)\n","\n","# backward\n","dprice = 1\n","dall_price, dtax = mul_tax_layer.backward(dprice)\n","dapple_price, dorange_price = add_apple_orange_layer.backward(dall_price)\n","dorange, dorange_num = mul_orange_layer.backward(dorange_price)\n","dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n","\n","print(price)\n","print(dapple_num, dapple, dorange, dorange_num, dtax)"],"metadata":{"id":"ymwEVz5148rP"},"id":"ymwEVz5148rP","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 活性化関数レイヤの実装"],"metadata":{"id":"v5L5wQC58Dc3"},"id":"v5L5wQC58Dc3"},{"cell_type":"markdown","source":["ReLUレイヤ"],"metadata":{"id":"QAFn6YAX8mdo"},"id":"QAFn6YAX8mdo"},{"cell_type":"code","source":["class Relu:\n","  def __init__(self):\n","    self.mask = None\n","\n","  def forward(self, x):\n","    self.mask = (x <= 0)\n","    out = x.copy()\n","    out[self.mask] = 0\n","\n","    return out\n","\n","  def backword(self, dout):\n","    dout[self.mask] = 0\n","    dx = dout\n","\n","    return dx"],"metadata":{"id":"bstxyiUc8qIM"},"id":"bstxyiUc8qIM","execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = np.array([[1.0, -0.5], [-2.0, 3.0]])\n","print(x)\n","\n","mask = (x <= 0)\n","print(mask)"],"metadata":{"id":"fwayu12q-SAn"},"id":"fwayu12q-SAn","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["trueの場所を０に\n","\n","ReLUレイヤは、回路における「スイッチ」のように機能する"],"metadata":{"id":"VEBYjUMT_OpC"},"id":"VEBYjUMT_OpC"},{"cell_type":"markdown","source":["Sigmoidレイヤ"],"metadata":{"id":"5pXOObUL-2Bq"},"id":"5pXOObUL-2Bq"},{"cell_type":"code","source":["class Sigmoid:\n","  def __init__(self):\n","    self.out = None\n","\n","  def forward(self, x):\n","    out = 1 / (1 + np.exp(-x))\n","    self.out = out\n","\n","    return out\n","\n","  def backward(self, dout):\n","    dx = dout * (1.0 - self.out) * self.out\n","\n","    return dx"],"metadata":{"id":"niuEbxdXAAJn"},"id":"niuEbxdXAAJn","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Affine / Softmaxレイヤの実装"],"metadata":{"id":"_2_tcu6BE_-E"},"id":"_2_tcu6BE_-E"},{"cell_type":"markdown","source":["Affineレイヤ\n","\n","バッチ版Affineレイヤ"],"metadata":{"id":"_YjkN8HGa0q9"},"id":"_YjkN8HGa0q9"},{"cell_type":"markdown","source":["バッチ＝データのまとまり"],"metadata":{"id":"72scmcLEa-uT"},"id":"72scmcLEa-uT"},{"cell_type":"code","source":["class Affine:\n","  def __init__(self, W, b):\n","    self.W = W\n","    self.b = b\n","    self.x = None\n","    self.dW = None\n","    self.db = None\n","\n","  def forward(self, x):\n","    self.x = x\n","    out = np.dot(x, self.W) + self.b\n","\n","    return out\n","\n","  def backward(self, dout):\n","    dx = np.dot(dout, self.W.T)\n","    self.dW = np.dot(self.x.T, dout)\n","    self.db = np.sum(dout, axis=0)\n","\n","    return dx"],"metadata":{"id":"COd-LZ0mFMFn"},"id":"COd-LZ0mFMFn","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Softmax-with-Lossレイヤ"],"metadata":{"id":"xCas6F0geQYr"},"id":"xCas6F0geQYr"},{"cell_type":"code","source":["class SoftmaxWithLoss:\n","  def __init__(self):\n","    self.loss = None  # 損失\n","    self.y = None # softmaxの出力\n","    self.t = None # 教師データ（one-hot vector）\n","\n","  def forward(self, x, t):\n","    self.t = t\n","    self.y = softmax(x)\n","    self.loss = cross_entropy_error(self.y, self.t)\n","\n","    return self.loss\n","\n","  def backward(self, dout=1):\n","    batch_size = self.t.shape[0]\n","    dx = (self.y - self.t) / batch_size\n","\n","    return dx"],"metadata":{"id":"H_3hnmkSfJ2k"},"id":"H_3hnmkSfJ2k","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 誤差逆伝播法の実装"],"metadata":{"id":"2za2hkuSkIfz"},"id":"2za2hkuSkIfz"},{"cell_type":"markdown","source":["ニューラルネットワークの学習の全体図"],"metadata":{"id":"Lg1tSZWRkXsy"},"id":"Lg1tSZWRkXsy"},{"cell_type":"markdown","source":["前提\n","\n","> ニューラルネットワークは、適応可能な重みとバイアスがあり、この重みとバイアスを訓練データに適応するように調整することを「学習」と呼ぶ。ニューラルネットワークの学習は次の４つの手順で行う。\n","\n","ステップ１（ミニバッチ）\n","\n","> 訓練データの中からランダムに一部のデータを選び出す。\n","\n","ステップ２（勾配の算出）\n","\n","> 各重みパラメータに関する損失関数の勾配を求める。\n","\n","ステップ３（パラメータの更新）\n","\n","> 重みパラメータを勾配方向に微小量だけ更新する。\n","\n","ステップ４（繰り返す）\n","\n","> ステップ１、ステップ２，ステップ３を繰り返す。"],"metadata":{"id":"CvOOa7VAkdD5"},"id":"CvOOa7VAkdD5"},{"cell_type":"markdown","source":["誤差逆伝播法に対応したニューラルネットワークの実装"],"metadata":{"id":"-eBsLw1AlZpG"},"id":"-eBsLw1AlZpG"},{"cell_type":"markdown","source":["２層のニューラルネットワークをTwoLayerNetとして実装"],"metadata":{"id":"6TcDgPILnJN3"},"id":"6TcDgPILnJN3"},{"cell_type":"code","source":["import sys, os\n","sys.path.append(os.pardir)\n","import numpy as np\n","from common.layers import *\n","from common.gradient import numerical_gradient\n","from collections import OrderedDict\n","\n","class TwoLayerNet:\n","  def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n","    # 重みの初期化\n","    self.params = {}\n","    self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n","    self.params['b1'] = np.zeros(hidden_size)\n","    self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n","    self.params['b2'] = np.zeros(output_size)\n","\n","    # レイヤの生成\n","    self.layers = OrderedDict()\n","    self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])\n","    self.layers['Relu1'] = Relu()\n","    self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])\n","\n","    self.lastLayer = SoftmaxWithLoss()\n","\n","\n","  def predict(self, x):\n","    for layer in self.layers.values():\n","      x = layer.forward(x)\n","\n","    return x\n","\n","  \n","  # ｘ：入力データ、ｔ：教師データ\n","  def loss(self, x, t):\n","    y = self.predict(x)\n","    return self.lastLayer.forward(y, t)\n","\n","\n","  def accuracy(self, x, t):\n","    y = self.predict(x)\n","    y = np.argmax(y, axis=1)\n","    if t.ndim != 1 : t = np.argmax(t, axis=1)\n","\n","    accuracy = np.sum(y == t) / float(x.shape[0])\n","    return accuracy\n","\n","\n","  def numerical_gradient(self, x, t):\n","    loss_W = lambda W: self.loss(x, t)\n","\n","    grads = {}\n","    grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n","    grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n","    grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n","    grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n","\n","    return grads\n","\n","\n","  def gradient(self, x, t):\n","    # forward\n","    self.loss(x, t)\n","\n","    # backward\n","    dout = 1\n","    dout = self.lastLayer.backward(dout)\n","\n","    layers = list(self.layers.values())\n","    layers.reverse()\n","    for layer in layers:\n","      dout = layer.backward(dout)\n","\n","    # 設定\n","    grads = {}\n","    grads['W1'] = self.layers['Affine1'].dW\n","    grads['b1'] = self.layers['Affine1'].db\n","    grads['W2'] = self.layers['Affine2'].dW\n","    grads['b2'] = self.layers['Affine2'].db\n","\n","    return grads\n","\n"],"metadata":{"id":"rp9wTtRdpLzq"},"id":"rp9wTtRdpLzq","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["誤差逆伝播法の勾配確認"],"metadata":{"id":"xul__1-qJbzJ"},"id":"xul__1-qJbzJ"},{"cell_type":"code","source":["import sys, os\n","sys.path.append(os.pardir)\n","import numpy as np\n","from dataset.mnist import load_mnist\n","from ch04.two_layer_net import TwoLayerNet\n","\n","# データの読み込み\n","(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n","\n","network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n","\n","x_batch = x_train[:3]\n","t_batch = t_train[:3]\n","\n","grad_numerical = network.numerical_gradient(x_batch, t_batch)\n","grad_backprop = network.gradient(x_batch, t_batch)\n","\n","# 各重みの誤差の平均を求める\n","for key in grad_numerical.keys():\n","  diff = np.average(np.abs(grad_backprop[key] - grad_numerical[key]))\n","  print(key + \":\" + str(diff))"],"metadata":{"id":"DMpaSLvVKnnT"},"id":"DMpaSLvVKnnT","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["誤差逆伝播法を使った学習"],"metadata":{"id":"xEPo9Ol0LYYA"},"id":"xEPo9Ol0LYYA"},{"cell_type":"code","source":["import sys, os\n","sys.path.append(os.pardir)\n","import numpy as np\n","from dataset.mnist import load_mnist\n","from ch04.two_layer_net import TwoLayerNet\n","\n","import sys, os\n","sys.path.append(os.pardir)\n","import numpy as np\n","from dataset.mnist import load_mnist\n","from ch04.two_layer_net import TwoLayerNet\n","\n","# データの読み込み\n","(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n","\n","network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n","\n","iters_num = 10000\n","train_size = x_train.shape[0]\n","batch_size = 100\n","learning_rate = 0.1\n","\n","train_loss_list = []\n","train_acc_list = []\n","test_acc_list = []\n","\n","iter_per_epoch = max(train_size / batch_size, 1)\n","\n","for i in range(iters_num):\n","  batch_mask = np.random.choice(train_size, batch_size)\n","  x_batch = x_train[batch_mask]\n","  t_batch = t_train[batch_mask]\n","\n","  # 誤差逆伝播法によって勾配を求める\n","  grad = network.gradient(x_batch, t_batch)\n","\n","  # 更新\n","  for key in (\"W1\", 'b1', 'W2', 'b2'):\n","    network.params[key] -= learning_rate * grad[key]\n","\n","  loss = network.loss(x_batch, t_batch)\n","  train_loss_list.append(loss)\n","\n","  if i % iter_per_epoch == 0:\n","    train_acc = network.accuracy(x_train, t_train)\n","    test_acc = network.accuracy(x_test, t_test)\n","    train_acc_list.append(train_acc)\n","    test_acc_list.append(test_acc)\n","    print(train_acc, test_acc)\n"],"metadata":{"id":"xLDk1syNNXgI"},"id":"xLDk1syNNXgI","execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_mask"],"metadata":{"id":"kvzgUESpVAHy"},"id":"kvzgUESpVAHy","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 学習に関するテクニック"],"metadata":{"id":"OdF06NQyVit2"},"id":"OdF06NQyVit2"},{"cell_type":"markdown","source":["## パラメータの更新"],"metadata":{"id":"wH5z9QVO-_92"},"id":"wH5z9QVO-_92"},{"cell_type":"markdown","source":["### 確率的勾配降下法 SGD"],"metadata":{"id":"xoWzj9xy_SlB"},"id":"xoWzj9xy_SlB"},{"cell_type":"code","source":["class SGD:\n","  def __init__(self, lr=0.01):\n","    self.lr = lr\n","\n","  def update(self, params, grads):\n","    for key in params.keys():\n","      params[key] -= self.lr * grads[key]"],"metadata":{"id":"BoBezrtf_O5X"},"id":"BoBezrtf_O5X","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["optimizer 最適化を行う者"],"metadata":{"id":"F-Ob4BNkCFfE"},"id":"F-Ob4BNkCFfE"},{"cell_type":"markdown","source":["SGDの欠点\n","\n","関数の形状が等方的でないと―伸びた形の関数だと―、非効率な経路で探索することになる"],"metadata":{"id":"8DkiPxR5Avod"},"id":"8DkiPxR5Avod"},{"cell_type":"markdown","source":["### Momentum"],"metadata":{"id":"b0jHxXjyD0fq"},"id":"b0jHxXjyD0fq"},{"cell_type":"markdown","source":["ボールがお盆を転がるように物理法則に準じる動きをする"],"metadata":{"id":"DrdRWx4xOrEY"},"id":"DrdRWx4xOrEY"},{"cell_type":"code","source":["class Momentum:\n","  def __init__(self, lr=0.01, momentum=0.9):\n","    self.lr = lr\n","    self.momentum = momentum\n","    self.v = None\n","\n","  def update(self, params, grads):\n","    if self.v is None:\n","      self.v = {}\n","      for key, val in params.items():\n","        self.v[key] = np.zeros_like(val)\n","\n","    for key in params.keys():\n","      self.v[key] = self.momentum*self.v[key] - self.lr*grads[key]\n","      params[key] += self.v[key]"],"metadata":{"id":"uy0LbLgDCcN8"},"id":"uy0LbLgDCcN8","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["ｙ軸方向の速度は安定しない\n","\n","ｘ軸方向へ速く近づくことができる"],"metadata":{"id":"SSIwbTYDIQOZ"},"id":"SSIwbTYDIQOZ"},{"cell_type":"markdown","source":["### AdaGrad"],"metadata":{"id":"YxslZqJdHRNT"},"id":"YxslZqJdHRNT"},{"cell_type":"markdown","source":["学習係数の減衰"],"metadata":{"id":"mNQo24FnIoez"},"id":"mNQo24FnIoez"},{"cell_type":"markdown","source":["パラメータの要素ごとに、適応的に更新ステップを調整"],"metadata":{"id":"4B__85f5OIuB"},"id":"4B__85f5OIuB"},{"cell_type":"code","source":["class AdaGrad:\n","  def __init__(self, lr=0.01):\n","    self.lr = lr\n","    self.h = None\n","\n","  def update(self, params, grads):\n","    if self.h is None:\n","      self.h = {}\n","      for key, val in params.items():\n","        self.h[key] = np.zeros_like(val)\n","\n","    for key in params.keys():\n","      self.h[key] * grads[key]\n","      params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)"],"metadata":{"id":"GXnhVhsIJAPG"},"id":"GXnhVhsIJAPG","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["効率的に動いている\n","\n","ｙ軸方向へは勾配が大きい勾配が大きいため、最初は大きく動くが、その大きさに比例して、更新のステップが小さくなる"],"metadata":{"id":"REcCGk0NMAjS"},"id":"REcCGk0NMAjS"},{"cell_type":"markdown","source":["### Adam"],"metadata":{"id":"TVfzCM7hNUTY"},"id":"TVfzCM7hNUTY"},{"cell_type":"markdown","source":["MomentumとAdaGradを融合したような手法"],"metadata":{"id":"zDYYtIABNfPJ"},"id":"zDYYtIABNfPJ"},{"cell_type":"markdown","source":["## 重みの初期化"],"metadata":{"id":"Jj6B2auSOvp_"},"id":"Jj6B2auSOvp_"},{"cell_type":"markdown","source":["過学習を抑え、汎化性能を高めるテクニック　Weight decay（荷重減衰）\n","\n","重みの初期値を０にしてはいけない"],"metadata":{"id":"dkQOClcmPU1F"},"id":"dkQOClcmPU1F"},{"cell_type":"code","source":["import sys, os\n","sys.path.append(os.pardir)\n","\n","from ch06 import weight_init_activation_histogram"],"metadata":{"id":"-ILXdFfFoVLH"},"id":"-ILXdFfFoVLH","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["勾配消失：逆伝播での勾配の値がどんどん小さくなって消えてしまう\n","\n","層を深くするディープラーニングでは深刻な問題"],"metadata":{"id":"nAllzCXIowoT"},"id":"nAllzCXIowoT"},{"cell_type":"markdown","source":["重みの標準偏差を0.01として同じ実験を行う"],"metadata":{"id":"C03kXL4ZpXkX"},"id":"C03kXL4ZpXkX"},{"cell_type":"code","source":["# coding: utf-8\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","\n","def sigmoid(x):\n","    return 1 / (1 + np.exp(-x))\n","\n","\n","def ReLU(x):\n","    return np.maximum(0, x)\n","\n","\n","def tanh(x):\n","    return np.tanh(x)\n","    \n","input_data = np.random.randn(1000, 100)  # 1000個のデータ\n","node_num = 100  # 各隠れ層のノード（ニューロン）の数\n","hidden_layer_size = 5  # 隠れ層が5層\n","activations = {}  # ここにアクティベーションの結果を格納する\n","\n","x = input_data\n","\n","for i in range(hidden_layer_size):\n","    if i != 0:\n","        x = activations[i-1]\n","\n","    # 初期値の値をいろいろ変えて実験しよう！\n","    # w = np.random.randn(node_num, node_num) * 1\n","    # w = np.random.randn(node_num, node_num) * 0.01\n","    # w = np.random.randn(node_num, node_num) * np.sqrt(1.0 / node_num)\n","    w = np.random.randn(node_num, node_num) * np.sqrt(2.0 / node_num)\n","\n","\n","    a = np.dot(x, w)\n","\n","\n","    # 活性化関数の種類も変えて実験しよう！\n","    # z = sigmoid(a)\n","    # z = ReLU(a)\n","    z = tanh(a)\n","\n","    activations[i] = z\n","\n","# ヒストグラムを描画\n","for i, a in activations.items():\n","    plt.subplot(1, len(activations), i+1)\n","    plt.title(str(i+1) + \"-layer\")\n","    if i != 0: plt.yticks([], [])\n","    # plt.xlim(0.1, 1)\n","    # plt.ylim(0, 7000)\n","    plt.hist(a.flatten(), 30, range=(0,1))\n","plt.show()"],"metadata":{"id":"jrbEzNIHrfpr"},"id":"jrbEzNIHrfpr","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["アクティベーションの偏りは「表現力の制限」の点で問題\n","\n","Xavierの初期値 これまでよりも広がりを持った分布 効率的な学習が期待できる"],"metadata":{"id":"bhlVkfmArt2q"},"id":"bhlVkfmArt2q"},{"cell_type":"markdown","source":["ReLUを用いるときはReLUに特化した初期値を用いることが推奨されている\n","\n","Heの初期値 データの広がりが層を深くしても均一に保たれる"],"metadata":{"id":"tsce4j1IsBNd"},"id":"tsce4j1IsBNd"},{"cell_type":"code","source":["import ch06.weight_init_compare"],"metadata":{"id":"M3g6GdNau6JT"},"id":"M3g6GdNau6JT","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["std=0.01\n","> 全く学習ができていない\n","\n","XavierとHeの初期値\n","> 順調に学習が行われている\n","\n","「Heの初期値」のほうが学習の進みが速い"],"metadata":{"id":"-ozJxo7hv5FJ"},"id":"-ozJxo7hv5FJ"},{"cell_type":"markdown","source":["## Batch Normalization"],"metadata":{"id":"xlu2-pEewtb_"},"id":"xlu2-pEewtb_"},{"cell_type":"markdown","source":["重みの初期値を適切に設定すれば、学習がスムーズに行える"],"metadata":{"id":"AOpH_fYTwyN6"},"id":"AOpH_fYTwyN6"},{"cell_type":"markdown","source":["強制的にアクティベーションの分布を調製しよう調整しよう → Batch Normalization"],"metadata":{"id":"GZmKpsM_xOsu"},"id":"GZmKpsM_xOsu"},{"cell_type":"markdown","source":["Batch Normalizationのいいところ\n","\n","- 学習を速く進行させることができる\n","- 初期値にそれほど依存しない\n","- 過学習を抑制する"],"metadata":{"id":"gzaaLBZNxmNr"},"id":"gzaaLBZNxmNr"},{"cell_type":"markdown","source":["学習を行う際のミニバッチを単位として、ミニバッチごとに正規化を行う\n","\n","データの分布の平均が0で分散が１になるように"],"metadata":{"id":"hALuocU6yVu7"},"id":"hALuocU6yVu7"},{"cell_type":"code","source":["import imp\n","import ch06.batch_norm_test\n","imp.reload(ch06.batch_norm_test)"],"metadata":{"id":"dUQeQLxKyymh"},"id":"dUQeQLxKyymh","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 正則化"],"metadata":{"id":"XauVBKquzWo_"},"id":"XauVBKquzWo_"},{"cell_type":"markdown","source":["過学習\n","\n","起きる原因\n","- パラメータを大量に持ち、表現力の高いモデルであること\n","- 訓練データが少ないこと"],"metadata":{"id":"Of6YULDMz2GS"},"id":"Of6YULDMz2GS"},{"cell_type":"code","source":["# coding: utf-8\n","import os\n","import sys\n","\n","sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from dataset.mnist import load_mnist\n","from common.multi_layer_net import MultiLayerNet\n","from common.optimizer import SGD\n","\n","(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n","\n","# 過学習を再現するために、学習データを削減\n","x_train = x_train[:300]\n","t_train = t_train[:300]\n","\n","# weight decay（荷重減衰）の設定 =======================\n","weight_decay_lambda = 0 # weight decayを使用しない場合\n","# weight_decay_lambda = 0.1\n","# ====================================================\n","\n","network = MultiLayerNet(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100], output_size=10,\n","                        weight_decay_lambda=weight_decay_lambda)\n","optimizer = SGD(lr=0.01)\n","\n","max_epochs = 201\n","train_size = x_train.shape[0]\n","batch_size = 100\n","\n","train_loss_list = []\n","train_acc_list = []\n","test_acc_list = []\n","\n","iter_per_epoch = max(train_size / batch_size, 1)\n","epoch_cnt = 0\n","\n","for i in range(1000000000):\n","    batch_mask = np.random.choice(train_size, batch_size)\n","    x_batch = x_train[batch_mask]\n","    t_batch = t_train[batch_mask]\n","\n","    grads = network.gradient(x_batch, t_batch)\n","    optimizer.update(network.params, grads)\n","\n","    if i % iter_per_epoch == 0:\n","        train_acc = network.accuracy(x_train, t_train)\n","        test_acc = network.accuracy(x_test, t_test)\n","        train_acc_list.append(train_acc)\n","        test_acc_list.append(test_acc)\n","\n","        print(\"epoch:\" + str(epoch_cnt) + \", train acc:\" + str(train_acc) + \", test acc:\" + str(test_acc))\n","\n","        epoch_cnt += 1\n","        if epoch_cnt >= max_epochs:\n","            break\n","\n","\n","# 3.グラフの描画==========\n","markers = {'train': 'o', 'test': 's'}\n","x = np.arange(max_epochs)\n","plt.plot(x, train_acc_list, marker='o', label='train', markevery=10)\n","plt.plot(x, test_acc_list, marker='s', label='test', markevery=10)\n","plt.xlabel(\"epochs\")\n","plt.ylabel(\"accuracy\")\n","plt.ylim(0, 1.0)\n","plt.legend(loc='lower right')\n","plt.show()"],"metadata":{"id":"kA9SD2VfaHlV"},"id":"kA9SD2VfaHlV","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["訓練データに適応しすぎている"],"metadata":{"id":"Ug3ktR06P0Mc"},"id":"Ug3ktR06P0Mc"},{"cell_type":"markdown","source":["Weight decay"],"metadata":{"id":"SFXr0ZfnaCwp"},"id":"SFXr0ZfnaCwp"},{"cell_type":"code","source":["import ch06.overfit_weight_decay\n","import imp\n","imp.reload(ch06.overfit_weight_decay)"],"metadata":{"id":"A9RWYXlVObkJ"},"id":"A9RWYXlVObkJ","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["過学習が抑制されている\n","\n","訓練データの認識精度が100%に到達していない"],"metadata":{"id":"GsmElIB-cQH4"},"id":"GsmElIB-cQH4"},{"cell_type":"markdown","source":["Dropout"],"metadata":{"id":"3tGGLcuYblS3"},"id":"3tGGLcuYblS3"},{"cell_type":"markdown","source":["モデルが複雑になってくるとWeight decayだけでは対応が困難に\n","\n","Dropout\n","> ランダムにニューロンを削除しながら学習する手法"],"metadata":{"id":"lp6XRaE9bvnj"},"id":"lp6XRaE9bvnj"},{"cell_type":"code","source":["class Dropout:\n","  def __init__(self, dropout_ratio=0.5):\n","    self.dropout_ratio = dropout_ratio\n","    self.mask = None\n","\n","  def forward(self, x, train_flg=True):\n","    if train_flg:\n","      self.mask = np.random.rand(*x.shape) > self.dropout_ratio\n","      return x * self.mask\n","    else:\n","      return x * (1.0 - self.dropout_ratio)\n","\n","  def backward(self, dout):\n","    return dout * self.mask"],"metadata":{"id":"wHfXmf1ZcHS1"},"id":"wHfXmf1ZcHS1","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["順伝播のたびに、self.maskに消去するニューロンをFalseとして格納する"],"metadata":{"id":"tM6Xk8ked1CC"},"id":"tM6Xk8ked1CC"},{"cell_type":"code","source":["import ch06.overfit_dropout"],"metadata":{"id":"PgLjbzCGdbIb"},"id":"PgLjbzCGdbIb","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## ハイパーパラメータの検証"],"metadata":{"id":"WbnIOIDKeTiq"},"id":"WbnIOIDKeTiq"},{"cell_type":"markdown","source":["ハイパーパラメータを調整する際には、ハイパーパラメータ専用の確認データが必要になる\n","\n","一般に**検証データ**と呼ぶ"],"metadata":{"id":"_RwAmJPDeuHZ"},"id":"_RwAmJPDeuHZ"},{"cell_type":"code","source":["from common.util import shuffle_dataset\n","\n","(x_train, t_train), (x_test, t_test) = load_mnist()\n","\n","# 訓練データをシャッフル\n","x_train,t_train = shuffle_dataset(x_train, t_train)\n","\n","# 検証データの分割\n","validation_rate = 0.20\n","validation_num = int(x_train.shape[0] * validation_rate)\n","\n","x_val = x_train[:validation_num]\n","t_val = t_train[:validation_num]\n","x_train = x_train[validation_num:]\n","t_train = t_train[validation_num:]\n"],"metadata":{"id":"ImN0syzyfVEn"},"id":"ImN0syzyfVEn","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["ハイパーパラメータの最適化"],"metadata":{"id":"8nN8uI2bbdAs"},"id":"8nN8uI2bbdAs"},{"cell_type":"markdown","source":["「良い値」が存在する範囲を徐々に絞り込んでいく\n","\n","グリッドサーチよりもランダムにサンプリングして探索するほうがいい結果になる"],"metadata":{"id":"ogZkrgtPb6vV"},"id":"ogZkrgtPb6vV"},{"cell_type":"markdown","source":["ステップ0\n","> ハイバーバラメータの範囲を設定する。\n","\n","ステップ1\n","> 設定されたハイバーバラメータの範囲から、ランダムにサンプリングする。\n","\n","ステップ2\n","> ステップ1でサンプリングされたハイバーパラメータの値を使用して学習を行い、検証\n","データで認識精度を評価する(ただし、エポックは小さく設定)。\n","\n","ステップ3\n","> ステフプ1とステップ2をある回数（100目など）繰り返し、それらの認強精度の結果から、ハイバーバラメータの範囲を狭める。\n","\n","上記を繰り返し行い,ハイバーバラメータの範囲を絞り込んでいき、ある程度酸り込んだ段階で、その絞り込んだ範囲からハイバーバラメータの値をひとつ選び出します。"],"metadata":{"id":"SQVrvlefcIud"},"id":"SQVrvlefcIud"},{"cell_type":"markdown","source":["ハイパーパラメータ最適化の実装"],"metadata":{"id":"XPhcs-qldC2l"},"id":"XPhcs-qldC2l"},{"cell_type":"markdown","source":["学習係数とWeight decayの強さをコントロールする係数の２つを探索する"],"metadata":{"id":"uey1UxfWds4o"},"id":"uey1UxfWds4o"},{"cell_type":"code","source":["weight_decay = 10 ** np.random.uniform(-8, -4)\n","lr = 10 ** np.random.uniform(-6, -2)"],"metadata":{"id":"VUxJuqOJd6S7"},"id":"VUxJuqOJd6S7","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import ch06.hyperparameter_optimization"],"metadata":{"id":"IQthuZloeXbl"},"id":"IQthuZloeXbl","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## まとめ"],"metadata":{"id":"jKsnddCkeeFS"},"id":"jKsnddCkeeFS"},{"cell_type":"markdown","source":["パラメータの更新方法や、重みの初期値の与え方、また、Batch NormalizationやDropputなど、どれも頻繁に利用される技術"],"metadata":{"id":"aiSz830BeqV8"},"id":"aiSz830BeqV8"},{"cell_type":"markdown","source":["# ７章 畳み込みニューラルネットワーク"],"metadata":{"id":"uVCfxDx2e_IJ"},"id":"uVCfxDx2e_IJ"},{"cell_type":"markdown","source":["CNNのメカニズム"],"metadata":{"id":"ATSKOW4ffQHB"},"id":"ATSKOW4ffQHB"},{"cell_type":"markdown","source":["## 全体の構造"],"metadata":{"id":"82oh_5QjfKkt"},"id":"82oh_5QjfKkt"},{"cell_type":"markdown","source":["新たに「Convolution レイヤ（畳み込み層）」と「Pooling レイヤ（プーリング層）」が登場\n","\n","Affine-ReLU → Convolution-ReLU-(Pooling)"],"metadata":{"id":"olJIq_d2fNu4"},"id":"olJIq_d2fNu4"},{"cell_type":"markdown","source":["## 畳み込み層"],"metadata":{"id":"EKK8UBCR7RK2"},"id":"EKK8UBCR7RK2"},{"cell_type":"markdown","source":["全結合層の問題点"],"metadata":{"id":"t_2af27N859L"},"id":"t_2af27N859L"},{"cell_type":"markdown","source":["データの形状が”無視”されてしまう\n","\n","３次元データの汲み取るべき本質的なパターンを見逃しているかも"],"metadata":{"id":"DZNEz91U9Hdu"},"id":"DZNEz91U9Hdu"},{"cell_type":"markdown","source":["畳み込み層は、形状を維持する\n","\n","**特徴マップ**：畳み込み層の入出力データ\n","\n","**入力特徴マップ**：畳み込み層の入力データ\n","\n","**出力特徴マップ**：出力データ"],"metadata":{"id":"lIoA5DNC9bUn"},"id":"lIoA5DNC9bUn"},{"cell_type":"markdown","source":["畳み込み層\n","\n","パディング\n","\n","> 出力サイズの調整\n","\n","ストライド\n","\n","> フィルターの適用する間隔の指定\n","\n","入力サイズ（H，W）、フィルターサイズ（FH, FW）、出力サイズ（OH, OW）、パディングをP、ストライドをS\n","\n","$OH=\\frac{H+2P-FH}{S}+1$\n","\n","$OW=\\frac{W+2P-FW}{S}+1$\n","\n"],"metadata":{"id":"k6LDH6zG-vMj"},"id":"k6LDH6zG-vMj"},{"cell_type":"markdown","source":["割り切れるようにする"],"metadata":{"id":"4PLEF-BKFKoD"},"id":"4PLEF-BKFKoD"},{"cell_type":"markdown","source":["バッチ処理"],"metadata":{"id":"mO2LzwfCMuKc"},"id":"mO2LzwfCMuKc"},{"cell_type":"markdown","source":["## プーリング層"],"metadata":{"id":"OOtAsZB4FQd5"},"id":"OOtAsZB4FQd5"},{"cell_type":"markdown","source":["縦・横方向の空間を小さくする演算\n","\n","プーリング層の特徴\n","学習するパラメータがない\n","\n","チャンネル数は変化しない\n","\n","最小な位置変化に対してロバスト（頑健）\n","> ズレを吸収する"],"metadata":{"id":"fESnFvgfMR6M"},"id":"fESnFvgfMR6M"},{"cell_type":"markdown","source":["## Convolution / Poolingレイヤの実装"],"metadata":{"id":"PXz4JLtcNY3K"},"id":"PXz4JLtcNY3K"},{"cell_type":"markdown","source":["CNNは４次元配列を扱う"],"metadata":{"id":"7C8CYHRANfwi"},"id":"7C8CYHRANfwi"},{"cell_type":"markdown","source":["im2colによる展開\n","> フィルターにとって都合の良いように入力データを展開する"],"metadata":{"id":"msIrZyXHNvwV"},"id":"msIrZyXHNvwV"},{"cell_type":"code","source":["import sys, os\n","sys.path.append(os.pardir)\n","from common.util import im2col\n","\n","x1 = np.random.rand(1, 3, 7, 7) # バッチサイズ＝１、チャンネル＝３、7*7\n","col1 = im2col(x1, 5, 5, stride=1, pad=0)\n","print(col1.shape)\n","\n","x2 = np.random.rand(10, 3, 7, 7)\n","col2 = im2col(x2, 5, 5, stride=1, pad=0)\n","print(col2.shape)"],"metadata":{"id":"yTjmn4URN0VW"},"id":"yTjmn4URN0VW","execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Convolution:\n","  def __init__(self, W, b, stride=1, pad=0):\n","    self.W = W\n","    self.b = b\n","    self.stride = stride\n","    self.pad = pad\n","\n","  def forward(self, x):\n","    \"\"\"\n","    FN: Filter Number\n","    C: Channel\n","    FH: Filter Height\n","    FW: Filter Width\n","    \"\"\"\n","    FN, C, FH, FW = self.W.shape\n","    N, C, H, W = x.shape\n","    out_h = int(1 + (H + 2*self.pad - FH) / self.stride)\n","    out_w = int(1 + (W + 2*self.pad - FW) / self.stride)\n","\n","    col = im2col(x, FH, FW, self.stride, self.pad)\n","    col_W = self.W.reshape(FN, -1).T\n","    out = np.dot(col, col_W) + self.b\n","\n","    out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n","\n","    return out"],"metadata":{"id":"pOoTQl4VQkAy"},"id":"pOoTQl4VQkAy","execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Pooling:\n","  def __init__(self, pool_h, pool_w, stride=2, pad=0):\n","    self.pool_h = pool_h\n","    self.pol_w, pool_w\n","    self.stride = stride\n","    self.pad = pad\n","\n","  def forward(self, x):\n","    N, C, H, W = x.shape\n","    out_h = int(1 + (H - self.pool_h) / self.stride)\n","    out_w = int(1 + (W - self.pool_w) / self.stride)\n","\n","    # 展開\n","    col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n","    col = col.reshape(-1, self.pool_h*self.pool_w)\n","\n","    # 最大値\n","    out = np.max(col, axis=1)\n","\n","    # 整形\n","    out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n","\n","    return out"],"metadata":{"id":"LM7T2hq2TIzN"},"id":"LM7T2hq2TIzN","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## CNNの実装"],"metadata":{"id":"k6KrWW67W1Ca"},"id":"k6KrWW67W1Ca"},{"cell_type":"markdown","source":["Convolution - ReLU - Pooling - Affine - ReLU - Affine - Softmax"],"metadata":{"id":"HQuh-M42aRFR"},"id":"HQuh-M42aRFR"},{"cell_type":"code","source":["import sys, os\n","sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n","import pickle\n","import numpy as np\n","from collections import OrderedDict\n","from common.layers import *\n","from common.gradient import numerical_gradient\n","\n","\n","class SimpleConvNet:\n","  \"\"\"\n","    input_size : 入力サイズ（MNISTの場合は784）\n","    hidden_size_list : 隠れ層のニューロンの数のリスト（e.g. [100, 100, 100]）\n","    output_size : 出力サイズ（MNISTの場合は10）\n","    activation : 'relu' or 'sigmoid'\n","    weight_init_std : 重みの標準偏差を指定（e.g. 0.01）\n","    'relu'または'he'を指定した場合は「Heの初期値」を設定\n","    'sigmoid'または'xavier'を指定した場合は「Xavierの初期値」を設定\n","  \"\"\"\n","  def __init__(self, input_dim=(1, 28, 28),\n","               conv_param={'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n","               hidden_size=100, output_size=10, weight_init_std=0.01):\n","    filter_num = conv_param['filter_num']\n","    filter_size = conv_param['filter_size']\n","    filter_pad = conv_param['pad']\n","    filter_stride = conv_param['stride']\n","    input_size = input_dim[1]\n","    conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n","    pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n","\n","    # 重みの初期化\n","    self.params = {}\n","    self.params['W1'] = weight_init_std * np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n","    self.params['b1'] = np.zeros(filter_num)\n","    self.params['W2'] = weight_init_std * np.random.randn(pool_output_size, hidden_size)\n","    self.params['b2'] = np.zeros(hidden_size)\n","    self.params['W3'] = weight_init_std * np.random.randn(hidden_size, output_size)\n","    self.params['b3'] = np.zeros(output_size)\n","\n","    # レイヤの生成\n","    self.layers = OrderedDict()\n","    self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'], conv_param['stride'], conv_param['pad'])\n","    self.layers['Relu1'] = Relu()\n","    self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n","    self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n","    self.layers['Relu2'] = Relu()\n","    self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n","\n","    self.last_layer = SoftmaxWithLoss()\n","\n","  def predict(self, x):\n","    for layer in self.layers.values():\n","      x = layer.forward(x)\n","\n","    return x\n","\n","  def loss(self, x, t):\n","    y = self.predict(x)\n","    return self.last_layer.forward(y, t)\n","\n","  def accuracy(self, x, t, batch_size=100):\n","    if t.ndim != 1 : t = np.argmax(t, axis=1)\n","\n","    acc = 0.0\n","\n","    for i in range(int(x.shape[0] / batch_size)):\n","      tx = x[i*batch_size:(i+1)*batch_size]\n","      tt = t[i*batch_size:(i+1)*batch_size]\n","      y = self.predict(tx)\n","      y = np.argmax(y, axis=1)\n","      acc += np.sum(y == tt)\n","\n","    return acc / x.shape[0]\n","\n","  def numerical_gradient(self, x, t):\n","    \"\"\"勾配を求める（数値微分）\n","\n","    Parameters\n","    ----------\n","    x : 入力データ\n","    t : 教師ラベル\n","\n","    Returns\n","    -------\n","    各層の勾配を持ったディクショナリ変数\n","        grads['W1']、grads['W2']、...は各層の重み\n","        grads['b1']、grads['b2']、...は各層のバイアス\n","    \"\"\"\n","    loss_w = lambda w: self.loss(x, t)\n","\n","    grads = {}\n","    for idx in (1, 2, 3):\n","      grads['W' + str(idx)] = numerical_gradient(loss_w, self.params['W' + str(idx)])\n","      grads['b' + str(idx)] = numerical_gradient(loss_w, self.params['b' + str(idx)])\n","\n","    return grads\n","\n","  def gradient(self, x, t):\n","    \"\"\"勾配を求める（誤差逆伝搬法）\n","\n","    Parameters\n","    ----------\n","    x : 入力データ\n","    t : 教師ラベル\n","\n","    Returns\n","    -------\n","    各層の勾配を持ったディクショナリ変数\n","        grads['W1']、grads['W2']、...は各層の重み\n","        grads['b1']、grads['b2']、...は各層のバイアス\n","    \"\"\"\n","    # forward\n","    self.loss(x, t)\n","\n","    # backward\n","    dout = 1\n","    dout = self.last_layer.backward(dout)\n","\n","    layers = list(self.layers.values())\n","    layers.reverse()\n","    for layer in layers:\n","      dout = layer.backward(dout)\n","\n","    # setting\n","    grads = {}\n","    grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n","    grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n","    grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n","\n","    return grads\n","\n","  def save_params(self, file_name=\"params.pkl\"):\n","      params = {}\n","      for key, val in self.params.items():\n","          params[key] = val\n","      with open(file_name, 'wb') as f:\n","          pickle.dump(params, f)\n","\n","  def load_params(self, file_name=\"params.pkl\"):\n","      with open(file_name, 'rb') as f:\n","          params = pickle.load(f)\n","      for key, val in params.items():\n","          self.params[key] = val\n","\n","      for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']):\n","          self.layers[key].W = self.params['W' + str(i+1)]\n","          self.layers[key].b = self.params['b' + str(i+1)]"],"metadata":{"id":"CsqqH-oiacmo"},"id":"CsqqH-oiacmo","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import sys, os\n","sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from dataset.mnist import load_mnist\n","# from simple_convnet import SimpleConvNet\n","from common.trainer import Trainer\n","\n","# データの読み込み\n","(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n","\n","max_epochs = 20\n","\n","network = SimpleConvNet(input_dim=(1,28,28), \n","                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n","                        hidden_size=100, output_size=10, weight_init_std=0.01)\n","\n","trainer = Trainer(network, x_train, t_train, x_test, t_test,\n","                  epochs=max_epochs, mini_batch_size=100,\n","                  optimizer='Adam', optimizer_param={'lr': 0.001},\n","                  evaluate_sample_num_per_epoch=1000)\n","trainer.train()\n","\n","# パラメータの保存\n","network.save_params(\"params.pkl\")\n","print(\"Saved Network Parameters!\")\n","\n","# グラフの描画\n","markers = {'train': 'o', 'test': 's'}\n","x = np.arange(max_epochs)\n","plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n","plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n","plt.xlabel(\"epochs\")\n","plt.ylabel(\"accuracy\")\n","plt.ylim(0, 1.0)\n","plt.legend(loc='lower right')\n","plt.show()"],"metadata":{"id":"F7tugzBW3s58"},"id":"F7tugzBW3s58","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## CNNの可視化"],"metadata":{"id":"r6naBYsV43pZ"},"id":"r6naBYsV43pZ"},{"cell_type":"code","source":["import ch07.visualize_filter"],"metadata":{"id":"SQ5e2bY36xcC"},"id":"SQ5e2bY36xcC","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 代表的なCNN"],"metadata":{"id":"s8RlQI--A7wj"},"id":"s8RlQI--A7wj"},{"cell_type":"markdown","source":["- LeNet\n","- AlexNet"],"metadata":{"id":"DnpOFk-9BgBW"},"id":"DnpOFk-9BgBW"},{"cell_type":"markdown","source":["## まとめ"],"metadata":{"id":"hBSoaOtFB3QW"},"id":"hBSoaOtFB3QW"},{"cell_type":"markdown","source":["CNNは、画像を扱う分野で頻繁に使われる"],"metadata":{"id":"A7lxJ7qgB5fr"},"id":"A7lxJ7qgB5fr"},{"cell_type":"markdown","source":["# ８章ディープラーニング"],"metadata":{"id":"Din3snyzCEhh"},"id":"Din3snyzCEhh"},{"cell_type":"markdown","source":["層を深くしたディープなニューラルネットワーク\n","\n","ディープラーニングの課題と性質、可能性について"],"metadata":{"id":"SUZK4bm9CJkS"},"id":"SUZK4bm9CJkS"},{"cell_type":"markdown","source":["## ネットワークをより深く"],"metadata":{"id":"-I27r-TJ44K7"},"id":"-I27r-TJ44K7"},{"cell_type":"markdown","source":["MNISTのデータセットを扱うよ"],"metadata":{"id":"oeJb06K249Aq"},"id":"oeJb06K249Aq"},{"cell_type":"markdown","source":["よりディープなネットワークへ"],"metadata":{"id":"dXOu4nfg5fOB"},"id":"dXOu4nfg5fOB"},{"cell_type":"markdown","source":["- ３×３の小さなフィルターによる畳み込み層\n","- 活性化関数は ReLU\n","- 全結合層の後に Dropout レイヤを使用\n","- Adam による最適化\n","- 重みの初期値として「He の初期値」を使用"],"metadata":{"id":"wGeXW8pI5j2L"},"id":"wGeXW8pI5j2L"},{"cell_type":"code","source":["from ch08.deep_convnet import DeepConvNet\n","\n","import sys, os\n","sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from dataset.mnist import load_mnist\n","# from simple_convnet import SimpleConvNet\n","from common.trainer import Trainer\n","\n","params_file = '/content/drive/MyDrive/Colab Notebooks/Book/deep-learning-from-scratch/ch08/deep_convnet_params.pkl'\n","\n","# データの読み込み\n","(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n","\n","max_epochs = 20\n","\n","network = DeepConvNet()\n","\n","network.load_params(file_name=params_file)\n","network.accuracy(x_train, t_train)\n","network.accuracy(x_test, t_test)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IxwoXaeW6aGu","executionInfo":{"status":"ok","timestamp":1653446950147,"user_tz":-540,"elapsed":432639,"user":{"displayName":"よしき","userId":"07538783130042353475"}},"outputId":"3f37f3f6-d54f-4d54-d616-f74f435de3c7"},"id":"IxwoXaeW6aGu","execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9935"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["さらに認識精度を高めるには\n","\n","- アンサンブル学習\n","- 学習係数の減衰\n","- データ拡張\n","\n","など"],"metadata":{"id":"WUx9K_Lf7Xh-"},"id":"WUx9K_Lf7Xh-"},{"cell_type":"markdown","source":["層を深くすることのモチベーション\n","\n","> 理論的にはあまり説明できていない\n","\n","> 層を深くすると認識性能も向上する\n","\n","利点\n","> ネットワークのパラメータ数を少なくできる\n","> 表現力も上がる\n","> 問題の細分化（解きやすいシンプルな問題に）\n"],"metadata":{"id":"L6S3rbkN8G6f"},"id":"L6S3rbkN8G6f"},{"cell_type":"markdown","source":["## ディープラーニングの小歴史"],"metadata":{"id":"kJA3W-JL8NSG"},"id":"kJA3W-JL8NSG"},{"cell_type":"markdown","source":["ImageNet\n","\n","VGG\n","\n","\n","googleNet：横方向にも幅がある\n","\n","ResNet：スキップ構造"],"metadata":{"id":"W7McX6_i9gGS"},"id":"W7McX6_i9gGS"},{"cell_type":"markdown","source":["## ディープラーニングの高速化"],"metadata":{"id":"okdvPpnT_8OR"},"id":"okdvPpnT_8OR"},{"cell_type":"markdown","source":["畳み込み層に多くの時間がかかる\n","\n","分散学習"],"metadata":{"id":"fFM4MufHAAX7"},"id":"fFM4MufHAAX7"},{"cell_type":"markdown","source":["## ディープラーニングの実用例"],"metadata":{"id":"sYxLHICLBZD4"},"id":"sYxLHICLBZD4"},{"cell_type":"markdown","source":["物体検出\n","\n","セグメンテーション\n","\n","画像キャプション生成"],"metadata":{"id":"HZPenQnMBdqJ"},"id":"HZPenQnMBdqJ"},{"cell_type":"markdown","source":["## ディープラーニングの未来"],"metadata":{"id":"EltGyHIkCoH0"},"id":"EltGyHIkCoH0"},{"cell_type":"markdown","source":["画像スタイル変換\n","\n","画像生成\n","\n","自動運転\n","\n","Deep Q-Network（強化学習）"],"metadata":{"id":"j8kNnJPQCrEc"},"id":"j8kNnJPQCrEc"},{"cell_type":"markdown","source":["## まとめ"],"metadata":{"id":"VU7m-m37D0B_"},"id":"VU7m-m37D0B_"},{"cell_type":"markdown","source":["ディープラーニングは分かっていないことも多くまだまだこれから"],"metadata":{"id":"5kJpfStLD25N"},"id":"5kJpfStLD25N"}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"colab":{"name":"deep-learning-from-scratch.ipynb","provenance":[],"collapsed_sections":["international-roads","polyphonic-brain","1e5f82cb","8118a9be","30c7aded","c39a44da","e769659f-9f37-438e-b6fa-f6a3d8c9cf20","c443c726-1f42-4981-92d8-f33237b32228","49215b42-fc3d-4129-87f6-8bd86feb872b","c2bebde4-dd1c-482b-ba57-56d2a13f4c23","90d81614-abd0-4b7d-ae31-88bd9ddbb917","d2248c8a-1bb4-455f-bb7c-da6fa47190fd","dLyE4O-AxCsv","fKgTsV7mVU-O","_rUvrSKnYFsG","c482OQo2Y90o","5zHSvCdNdHKE","eQTU3vce_TQd","mPJLPdbTIgRF","yh3EnF2HKaBB","8Ta_EnTlsR0Z","yH1WZAGrrFpf","0lo1kTF0tQpH","0rj0xTmOBE_2","XlAnJa0kA6zb","cGI8vLDbXQwC","vL3BDyeSBjjs","yS0AHKP4dZI5","uTPF5i-WiXOz","v5L5wQC58Dc3","_2_tcu6BE_-E","2za2hkuSkIfz","wH5z9QVO-_92","xoWzj9xy_SlB","b0jHxXjyD0fq","YxslZqJdHRNT","TVfzCM7hNUTY","Jj6B2auSOvp_","xlu2-pEewtb_","XauVBKquzWo_","WbnIOIDKeTiq","jKsnddCkeeFS"]},"accelerator":"TPU"},"nbformat":4,"nbformat_minor":5}